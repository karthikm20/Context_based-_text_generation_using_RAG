{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "# MODEL = \"gpt-3.5-turbo\"\n",
    "MODEL = \"llama2\"\n",
    "# MODEL = \"mixtral:8x7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dueling DQN (DDQN) is a type of deep reinforcement learning algorithm that combines two separate neural networks to learn both the policy and the value function of an agent simultaneously. The goal of DDQN is to learn a single neural network that can solve a given task by directly estimating both the policy and the value function.\\n\\nIn traditional Q-learning, the agent learns a policy that maps states to actions, and a value function that estimates the expected return for each state-action pair. However, this approach has some limitations. For example, it can be difficult to learn an accurate value function when the environment is complex or has a large state space. Additionally, learning both the policy and the value function separately can lead to suboptimal performance, as the policy may not take into account the information provided by the value function.\\n\\nDDQN addresses these limitations by using two separate neural networks to learn the policy and the value function simultaneously. The policy network maps states to actions, while the value network estimates the expected return for each state-action pair. During training, the agent observes the environment, takes an action according to the policy network, and receives a reward according to the environment. The agent then uses the value network to estimate the expected return of the action taken.\\n\\nDDQN has been shown to be effective in solving complex tasks, such as playing Atari games. By learning both the policy and the value function simultaneously, DDQN can learn more efficient policies and improve its performance compared to traditional Q-learning methods.\\n\\nThe key advantage of DDQN is that it allows for a more straightforward implementation of the Q-learning algorithm. Instead of learning two separate networks (policy and value), the agent learns a single network that can perform both tasks simultaneously. This can lead to simpler and more efficient training procedures, as well as improved performance in complex environments.\\n\\nHowever, DDQN also has some limitations. For example, it may be difficult to design the architecture of the neural networks in such a way that they can learn both the policy and the value function effectively. Additionally, the agent may require more data and training time to learn the joint policy and value functions compared to learning them separately.\\n\\nIn summary, Dueling DQN is a type of deep reinforcement learning algorithm that combines two separate neural networks to learn both the policy and the value function of an agent simultaneously. It has been shown to be effective in solving complex tasks, but also has some limitations that need to be considered when designing and training the agent.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "if MODEL.startswith(\"gpt\"):\n",
    "    model= ChatOpenAI(api_key=OPENAI_API_KEY, model=MODEL)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "else: \n",
    "    model=Ollama(model=MODEL)\n",
    "    embeddings = OllamaEmbeddings()\n",
    "model.invoke(\"What is Dueling DQN?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure! Here's a classic one:\\n\\nWhy don't scientists trust atoms?\\nBecause they make up everything!\\n\\nI hope that brought a smile to your face! Do you want to hear another one?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Used only for GPt Models\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser= StrOutputParser()\n",
    "\n",
    "chain = model | parser \n",
    "chain.invoke(\"Hey tell me a joke \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Understanding Diﬀusion Models: A Uniﬁed Perspective\\nCalvin Luo\\nGoogle Research, Brain Team\\ncalvinluo@google.com\\nAugust 26, 2022\\nContents\\nIntroduction: Generative Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\\nBackground: ELBO, VAE, and Hierarchical VAE . . . . . . . . . . . . . . . . . . . . . . . . 2\\nEvidence Lower Bound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\\nVariational Autoencoders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\nHierarchical Variational Autoencoders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\nVariational Diﬀusion Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\nLearning Diﬀusion Noise Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\nThree Equivalent Interpretations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\nScore-based Generative Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\nGuidance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\nClassiﬁer Guidance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\nClassiﬁer-Free Guidance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\nClosing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\\nIntroduction: Generative Models\\nGiven observed samples xfrom a distribution of interest, the goal of a generative model is to learn to\\nmodelits true data distribution p(x). Once learned, we can generate new samples from our approximate\\nmodel at will. Furthermore, under some formulations, we are able to use the learned model to evaluate the\\nlikelihood of observed or sampled data as well.\\nThereareseveralwell-knowndirectionsincurrentliterature, thatwewillonlyintroducebrieﬂyatahighlevel.\\nGenerative Adversarial Networks (GANs) model the sampling procedure of a complex distribution, which\\nis learned in an adversarial manner. Another class of generative models, termed \"likelihood-based\", seeks\\nto learn a model that assigns a high likelihood to the observed data samples. This includes autoregressive\\nmodels, normalizing ﬂows, and Variational Autoencoders (VAEs). Another similar approach is energy-based\\nmodeling, in which a distribution is learned as an arbitrarily ﬂexible energy function that is then normalized.\\n1arXiv:2208.11970v1  [cs.LG]  25 Aug 2022', metadata={'source': 'diffusion_models.pdf', 'page': 0}),\n",
       " Document(page_content='Score-based generative models are highly related; instead of learning to model the energy function itself, they\\nlearn the scoreof the energy-based model as a neural network. In this work we explore and review diﬀusion\\nmodels, which as we will demonstrate, have both likelihood-based and score-based interpretations. We\\nshowcase the math behind such models in excruciating detail, with the aim that anyone can follow along\\nand understand what diﬀusion models are and how they work.\\nBackground: ELBO, VAE, and Hierarchical VAE\\nFor many modalities, we can think of the data we observe as represented or generated by an associated\\nunseenlatentvariable, which we can denote by random variable z. The best intuition for expressing this\\nidea is through Plato’s Allegory of the Cave. In the allegory, a group of people are chained inside a cave their\\nentire life and can only see the two-dimensional shadows projected onto a wall in front of them, which are\\ngenerated by unseen three-dimensional objects passed before a ﬁre. To such people, everything they observe\\nis actually determined by higher-dimensional abstract concepts that they can never behold.\\nAnalogously, the objects that we encounter in the actual world may also be generated as a function of\\nsome higher-level representations; for example, such representations may encapsulate abstract properties\\nsuch as color, size, shape, and more. Then, what we observe can be interpreted as a three-dimensional\\nprojection or instantiation of such abstract concepts, just as what the cave people observe is actually a\\ntwo-dimensional projection of three-dimensional objects. Whereas the cave people can never see (or even\\nfully comprehend) the hidden objects, they can still reason and draw inferences about them; in a similar\\nway, we can approximate latent representations that describe the data we observe.\\nWhereas Plato’s Allegory illustrates the idea behind latent variables as potentially unobservable representa-\\ntions that determine observations, a caveat of this analogy is that in generative modeling, we generally seek\\nto learn lower-dimensional latent representations rather than higher-dimensional ones. This is because try-\\ning to learn a representation of higher dimension than the observation is a fruitless endeavor without strong\\npriors. On the other hand, learning lower-dimensional latents can also be seen as a form of compression, and\\ncan potentially uncover semantically meaningful structure describing observations.\\nEvidence Lower Bound\\nMathematically, we can imagine the latent variables and the data we observe as modeled by a joint distribu-\\ntionp(x,z). Recall one approach of generative modeling, termed \"likelihood-based\", is to learn a model to\\nmaximize the likelihood p(x)of all observed x. There are two ways we can manipulate this joint distribu-\\ntion to recover the likelihood of purely our observed data p(x); we can explicitly marginalize out the latent\\nvariablez:\\np(x) =∫\\np(x,z)dz (1)\\nor, we could also appeal to the chain rule of probability:\\np(x) =p(x,z)\\np(z|x)(2)\\nDirectly computing and maximizing the likelihood p(x)is diﬃcult because it either involves integrating out\\nall latent variables zin Equation 1, which is intractable for complex models, or it involves having access to a\\nground truth latent encoder p(z|x)in Equation 2. However, using these two equations, we can derive a term\\ncalled the EvidenceLowerBound (ELBO), which as its name suggests, is a lower bound of the evidence.\\nThe evidence is quantiﬁed in this case as the log likelihood of the observed data. Then, maximizing the\\nELBO becomes a proxy objective with which to optimize a latent variable model; in the best case, when the\\nELBO is powerfully parameterized and perfectly optimized, it becomes exactly equivalent to the evidence.\\nFormally, the equation of the ELBO is:\\nEqφ(z|x)[\\nlogp(x,z)\\nqφ(z|x)]\\n(3)\\n2', metadata={'source': 'diffusion_models.pdf', 'page': 1}),\n",
       " Document(page_content='To make the relationship with the evidence explicit, we can mathematically write:\\nlogp(x)≥Eqφ(z|x)[\\nlogp(x,z)\\nqφ(z|x)]\\n(4)\\nHere,qφ(z|x)is a ﬂexible approximate variational distribution with parameters φthat we seek to optimize.\\nIntuitively, it can be thought of as a parameterizable model that is learned to estimate the true distribution\\nover latent variables for given observations x; in other words, it seeks to approximate true posterior p(z|x).\\nAs we will see when exploring the Variational Autoencoder, as we increase the lower bound by tuning the\\nparametersφto maximize the ELBO, we gain access to components that can be used to model the true\\ndata distribution and sample from it, thus learning a generative model. For now, let us try to dive deeper\\ninto why the ELBO is an objective we would like to maximize.\\nLet us begin by deriving the ELBO, using Equation 1:\\nlogp(x) = log∫\\np(x,z)dz (Apply Equation 1) (5)\\n= log∫p(x,z)qφ(z|x)\\nqφ(z|x)dz (Multiply by 1 =qφ(z|x)\\nqφ(z|x)) (6)\\n= log Eqφ(z|x)[p(x,z)\\nqφ(z|x)]\\n(Deﬁnition of Expectation) (7)\\n≥Eqφ(z|x)[\\nlogp(x,z)\\nqφ(z|x)]\\n(Apply Jensen’s Inequality) (8)\\nIn this derivation, we directly arrive at our lower bound by applying Jensen’s Inequality. However, this does\\nnot supply us much useful information about what is actually going on underneath the hood; crucially, this\\nproof gives no intuition on exactly why the ELBO is actually a lower bound of the evidence, as Jensen’s\\nInequality handwaves it away. Furthermore, simply knowing that the ELBO is truly a lower bound of the\\ndatadoesnotreallytelluswhywewanttomaximizeitasanobjective. Tobetterunderstandtherelationship\\nbetween the evidence and the ELBO, let us perform another derivation, this time using Equation 2:\\nlogp(x) = logp(x)∫\\nqφ(z|x)dz (Multiply by 1 =∫\\nqφ(z|x)dz) (9)\\n=∫\\nqφ(z|x)(logp(x))dz (Bring evidence into integral) (10)\\n=Eqφ(z|x)[logp(x)] (Deﬁnition of Expectation) (11)\\n=Eqφ(z|x)[\\nlogp(x,z)\\np(z|x)]\\n(Apply Equation 2) (12)\\n=Eqφ(z|x)[\\nlogp(x,z)qφ(z|x)\\np(z|x)qφ(z|x)]\\n(Multiply by 1 =qφ(z|x)\\nqφ(z|x)) (13)\\n=Eqφ(z|x)[\\nlogp(x,z)\\nqφ(z|x)]\\n+Eqφ(z|x)[\\nlogqφ(z|x)\\np(z|x)]\\n(Split the Expectation) (14)\\n=Eqφ(z|x)[\\nlogp(x,z)\\nqφ(z|x)]\\n+DKL(qφ(z|x)∥p(z|x))(Deﬁnition of KL Divergence) (15)\\n≥Eqφ(z|x)[\\nlogp(x,z)\\nqφ(z|x)]\\n(KL Divergence always ≥0) (16)\\nFrom this derivation, we clearly observe from Equation 15 that the evidence is equal to the ELBO plus the\\nKL Divergence between the approximate posterior qφ(z|x)and the true posterior p(z|x). In fact, it was this\\nKL Divergence term that was magically removed by Jensen’s Inequality in Equation 8 of the ﬁrst derivation.\\nUnderstanding this term is the key to understanding not only the relationship between the ELBO and the\\nevidence, but also the reason why optimizing the ELBO is an appropriate objective at all.\\nFirstly, we now know why the ELBO is indeed a lower bound: the diﬀerence between the evidence and the\\nELBO is a strictly non-negative KL term, thus the value of the ELBO can never exceed the evidence.\\n3', metadata={'source': 'diffusion_models.pdf', 'page': 2}),\n",
       " Document(page_content='Figure 1: A Variational Autoencoder graphically represented. Here, encoder q(z|x)deﬁnes a distribution\\nover latent variables zfor observations x, andp(x|z)decodes latent variables into observations.\\nSecondly, we explore why we seek to maximize the ELBO. Having introduced latent variables zthat we\\nwould like to model, our goal is to learn this underlying latent structure that describes our observed data. In\\nother words, we want to optimize the parameters of our variational posterior qφ(z|x)to exactly match the\\ntrue posterior distribution p(z|x), which is achieved by minimizing their KL Divergence (ideally to zero).\\nUnfortunately, it is intractable to minimize this KL Divergence term directly, as we do not have access to the\\nground truth p(z|x)distribution. However, notice that on the left hand side of Equation 15, the likelihood of\\nour data (and therefore our evidence term logp(x)) is always a constant with respect to φ, as it is computed\\nby marginalizing out all latents zfrom the joint distribution p(x,z)and does not depend on φwhatsoever.\\nSince the ELBO and KL Divergence terms sum up to a constant, any maximization of the ELBO term with\\nrespect toφnecessarily invokes an equal minimization of the KL Divergence term. Thus, the ELBO can be\\nmaximized as a proxy for learning how to perfectly model the true latent posterior distribution; the more\\nwe optimize the ELBO, the closer our approximate posterior gets to the true posterior. Additionally, once\\ntrained, the ELBO can be used to estimate the likelihood of observed or generated data as well, since it is\\nlearned to approximate the model evidence logp(x).\\nVariational Autoencoders\\nIn the default formulation of the Variational Autoencoder (VAE) [1], we directly maximize the ELBO. This\\napproach is variational , because we optimize for the best qφ(z|x)amongst a family of potential posterior\\ndistributions parameterized by φ. It is called an autoencoder because it is reminiscent of a traditional au-\\ntoencoder model, where input data is trained to predict itself after undergoing an intermediate bottlenecking\\nrepresentation step. To make this connection explicit, let us dissect the ELBO term further:\\nEqφ(z|x)[\\nlogp(x,z)\\nqφ(z|x)]\\n=Eqφ(z|x)[\\nlogpθ(x|z)p(z)\\nqφ(z|x)]\\n(Chain Rule of Probability) (17)\\n=Eqφ(z|x)[logpθ(x|z)] +Eqφ(z|x)[\\nlogp(z)\\nqφ(z|x)]\\n(Split the Expectation) (18)\\n=Eqφ(z|x)[logpθ(x|z)]\\ued19\\ued18\\ued17\\ued1a\\nreconstruction term−DKL(qφ(z|x)∥p(z))\\ued19\\ued18\\ued17\\ued1a\\nprior matching term(Deﬁnition of KL Divergence) (19)\\nIn this case, we learn an intermediate bottlenecking distribution qφ(z|x)that can be treated as an encoder; it\\ntransforms inputs into a distribution over possible latents. Simultaneously, we learn a deterministic function\\npθ(x|z)to convert a given latent vector zinto an observation x, which can be interpreted as a decoder.\\nThe two terms in Equation 19 each have intuitive descriptions: the ﬁrst term measures the reconstruction\\nlikelihood of the decoder from our variational distribution; this ensures that the learned distribution is\\nmodeling eﬀective latents that the original data can be regenerated from. The second term measures how\\nsimilar the learned variational distribution is to a prior belief held over latent variables. Minimizing this\\nterm encourages the encoder to actually learn a distribution rather than collapse into a Dirac delta function.\\nMaximizing the ELBO is thus equivalent to maximizing its ﬁrst term and minimizing its second term.\\n4', metadata={'source': 'diffusion_models.pdf', 'page': 3}),\n",
       " Document(page_content='A deﬁning feature of the VAE is how the ELBO is optimized jointly over parameters φandθ. The encoder\\nof the VAE is commonly chosen to model a multivariate Gaussian with diagonal covariance, and the prior is\\noften selected to be a standard multivariate Gaussian:\\nqφ(z|x) =N(z;µφ(x),σ2\\nφ(x)I) (20)\\np(z) =N(z;0,I) (21)\\nThen, the KL divergence term of the ELBO can be computed analytically, and the reconstruction term can\\nbe approximated using a Monte Carlo estimate. Our objective can then be rewritten as:\\narg max\\nφ,θEqφ(z|x)[logpθ(x|z)]−DKL(qφ(z|x)∥p(z))≈arg max\\nφ,θL∑\\nl=1logpθ(x|z(l))−DKL(qφ(z|x)∥p(z))(22)\\nwhere latents{z(l)}L\\nl=1are sampled from qφ(z|x), for every observation xin the dataset. However, a problem\\narises in this default setup: each z(l)that our loss is computed on is generated by a stochastic sampling\\nprocedure,whichisgenerallynon-diﬀerentiable. Fortunately,thiscanbeaddressedviathe reparameterization\\ntrickwhenqφ(z|x)is designed to model certain distributions, including the multivariate Gaussian.\\nThe reparameterization trick rewrites a random variable as a deterministic function of a noise variable; this\\nallows for the optimization of the non-stochastic terms through gradient descent. For example, samples from\\na normal distribution x∼N(x;µ,σ2)with arbitrary mean µand variance σ2can be rewritten as:\\nx=µ+σϵwithϵ∼N(ϵ; 0,I)\\nIn other words, arbitrary Gaussian distributions can be interpreted as standard Gaussians (of which ϵis\\na sample) that have their mean shifted from zero to the target mean µby addition, and their variance\\nstretched by the target variance σ2. Therefore, by the reparameterization trick, sampling from an arbitrary\\nGaussian distribution can be performed by sampling from a standard Gaussian, scaling the result by the\\ntarget standard deviation, and shifting it by the target mean.\\nInaVAE,each zisthuscomputedasadeterministicfunctionofinput xandauxiliarynoisevariable ϵ:\\nz=µφ(x) +σφ(x)⊙ϵwithϵ∼N(ϵ;0,I)\\nwhere⊙represents an element-wise product. Under this reparameterized version of z, gradients can then\\nbe computed with respect to φas desired, to optimize µφandσφ. The VAE therefore utilizes the reparam-\\neterization trick and Monte Carlo estimates to optimize the ELBO jointly over φandθ.\\nAfter training a VAE, generating new data can be performed by sampling directly from the latent space p(z)\\nand then running it through the decoder. Variational Autoencoders are particularly interesting when the\\ndimensionality of zis less than that of input x, as we might then be learning compact, useful representations.\\nFurthermore, when a semantically meaningful latent space is learned, latent vectors can be edited before\\nbeing passed to the decoder to more precisely control the data generated.\\nHierarchical Variational Autoencoders\\nA Hierarchical Variational Autoencoder (HVAE) [2, 3] is a generalization of a VAE that extends to multi-\\nple hierarchies over latent variables. Under this formulation, latent variables themselves are interpreted as\\ngenerated from other higher-level, more abstract latents. Intuitively, just as we treat our three-dimensional\\nobserved objects as generated from a higher-level abstract latent, the people in Plato’s cave treat three-\\ndimensional objects as latents that generate their two-dimensional observations. Therefore, from the per-\\nspective of Plato’s cave dwellers, their observations can be treated as modeled by a latent hierarchy of depth\\ntwo (or more).\\nWhereas in the general HVAE with Thierarchical levels, each latent is allowed to condition on all previous\\nlatents, in this work we focus on a special case which we call a Markovian HVAE (MHVAE). In a MHVAE,\\nthe generative process is a Markov chain; that is, each transition down the hierarchy is Markovian, where\\n5', metadata={'source': 'diffusion_models.pdf', 'page': 4}),\n",
       " Document(page_content='Figure 2: A Markovian Hierarchical Variational Autoencoder with Thierarchical latents. The generative\\nprocess is modeled as a Markov chain, where each latent ztis generated only from the previous latent zt+1.\\ndecoding each latent ztonly conditions on previous latent zt+1. Intuitively, and visually, this can be seen\\nas simply stacking VAEs on top of each other, as depicted in Figure 2; another appropriate term describing\\nthis model is a Recursive VAE. Mathematically, we represent the joint distribution and the posterior of a\\nMarkovian HVAE as:\\np(x,z1:T) =p(zT)pθ(x|z1)T∏\\nt=2pθ(zt−1|zt) (23)\\nqφ(z1:T|x) =qφ(z1|x)T∏\\nt=2qφ(zt|zt−1) (24)\\nThen, we can easily extend the ELBO to be:\\nlogp(x) = log∫\\np(x,z1:T)dz1:T (Apply Equation 1) (25)\\n= log∫p(x,z1:T)qφ(z1:T|x)\\nqφ(z1:T|x)dz1:T (Multiply by 1 =qφ(z1:T|x)\\nqφ(z1:T|x)) (26)\\n= log Eqφ(z1:T|x)[p(x,z1:T)\\nqφ(z1:T|x)]\\n(Deﬁnition of Expectation) (27)\\n≥Eqφ(z1:T|x)[\\nlogp(x,z1:T)\\nqφ(z1:T|x)]\\n(Apply Jensen’s Inequality) (28)\\nWe can then plug our joint distribution (Equation 23) and posterior (Equation 24) into Equation 28 to\\nproduce an alternate form:\\nEqφ(z1:T|x)[\\nlogp(x,z1:T)\\nqφ(z1:T|x)]\\n=Eqφ(z1:T|x)[\\nlogp(zT)pθ(x|z1)∏T\\nt=2pθ(zt−1|zt)\\nqφ(z1|x)∏T\\nt=2qφ(zt|zt−1)]\\n(29)\\nAs we will show below, when we investigate Variational Diﬀusion Models, this objective can be further\\ndecomposed into interpretable components.\\nVariational Diﬀusion Models\\nThe easiest way to think of a Variational Diﬀusion Model (VDM) [4, 5, 6] is simply as a Markovian Hierar-\\nchical Variational Autoencoder with three key restrictions:\\n•The latent dimension is exactly equal to the data dimension\\n•The structure of the latent encoder at each timestep is not learned; it is pre-deﬁned as a linear Gaussian\\nmodel. Inotherwords, itisaGaussiandistributioncenteredaroundtheoutputoftheprevioustimestep\\n•The Gaussian parameters of the latent encoders vary over time in such a way that the distribution of\\nthe latent at ﬁnal timestep Tis a standard Gaussian\\n6', metadata={'source': 'diffusion_models.pdf', 'page': 5}),\n",
       " Document(page_content='Figure 3: A visual representation of a Variational Diﬀusion Model; x0represents true data observations such\\nas natural images, xTrepresents pure Gaussian noise, and xtis an intermediate noisy version of x0. Each\\nq(xt|xt−1)is modeled as a Gaussian distribution that uses the output of the previous state as its mean.\\nFurthermore, we explicitly maintain the Markov property between hierarchical transitions from a standard\\nMarkovian Hierarchical Variational Autoencoder.\\nLet us expand on the implications of these assumptions. From the ﬁrst restriction, with some abuse of\\nnotation, we can now represent both true data samples and latent variables as xt, wheret= 0represents\\ntrue data samples and t∈[1,T]represents a corresponding latent with hierarchy indexed by t. The VDM\\nposterior is the same as the MHVAE posterior (Equation 24), but can now be rewritten as:\\nq(x1:T|x0) =T∏\\nt=1q(xt|xt−1) (30)\\nFrom the second assumption, we know that the distribution of each latent variable in the encoder is a\\nGaussian centered around its previous hierarchical latent. Unlike a Markovian HVAE, the structure of the\\nencoder at each timestep tis not learned; it is ﬁxed as a linear Gaussian model, where the mean and standard\\ndeviation can be set beforehand as hyperparameters [5], or learned as parameters [6]. We parameterize the\\nGaussian encoder with mean µt(xt) =√αtxt−1, and variance Σt(xt) = (1−αt)I, where the form of the\\ncoeﬃcients are chosen such that the variance of the latent variables stay at a similar scale; in other words,\\nthe encoding process is variance-preserving . Note that alternate Gaussian parameterizations are allowed,\\nand lead to similar derivations. The main takeaway is that αtis a (potentially learnable) coeﬃcient that can\\nvary with the hierarchical depth t, for ﬂexibility. Mathematically, encoder transitions are denoted as:\\nq(xt|xt−1) =N(xt;√αtxt−1,(1−αt)I) (31)\\nFrom the third assumption, we know that αtevolves over time according to a ﬁxed or learnable schedule\\nstructuredsuchthatthedistributionoftheﬁnallatent p(xT)isastandardGaussian. Wecanthenupdatethe\\njoint distribution of a Markovian HVAE (Equation 23) to write the joint distribution for a VDM as:\\np(x0:T) =p(xT)T∏\\nt=1pθ(xt−1|xt) (32)\\nwhere,\\np(xT) =N(xT;0,I) (33)\\nCollectively, what this set of assumptions describes is a steady noisiﬁcation of an image input over time; we\\nprogressively corrupt an image by adding Gaussian noise until eventually it becomes completely identical to\\npure Gaussian noise. Visually, this process is depicted in Figure 3.\\n7', metadata={'source': 'diffusion_models.pdf', 'page': 6}),\n",
       " Document(page_content='Note that our encoder distributions q(xt|xt−1)are no longer parameterized by φ, as they are completely\\nmodeled as Gaussians with deﬁned mean and variance parameters at each timestep. Therefore, in a VDM, we\\nare only interested in learning conditionals pθ(xt−1|xt), so that we can simulate new data. After optimizing\\nthe VDM, the sampling procedure is as simple as sampling Gaussian noise from p(xT)and iteratively running\\nthe denoising transitions pθ(xt−1|xt)forTsteps to generate a novel x0.\\nLike any HVAE, the VDM can be optimized by maximizing the ELBO, which can be derived as:\\nlogp(x)=log∫\\np(x0:T)dx1:T (34)\\n=log∫p(x0:T)q(x1:T|x0)\\nq(x1:T|x0)dx1:T (35)\\n=logEq(x1:T|x0)[p(x0:T)\\nq(x1:T|x0)]\\n(36)\\n≥Eq(x1:T|x0)[\\nlogp(x0:T)\\nq(x1:T|x0)]\\n(37)\\n=Eq(x1:T|x0)[\\nlogp(xT)∏T\\nt=1pθ(xt−1|xt)\\n∏T\\nt=1q(xt|xt−1)]\\n(38)\\n=Eq(x1:T|x0)[\\nlogp(xT)pθ(x0|x1)∏T\\nt=2pθ(xt−1|xt)\\nq(xT|xT−1)∏T−1\\nt=1q(xt|xt−1)]\\n(39)\\n=Eq(x1:T|x0)[\\nlogp(xT)pθ(x0|x1)∏T−1\\nt=1pθ(xt|xt+1)\\nq(xT|xT−1)∏T−1\\nt=1q(xt|xt−1)]\\n(40)\\n=Eq(x1:T|x0)[\\nlogp(xT)pθ(x0|x1)\\nq(xT|xT−1)]\\n+Eq(x1:T|x0)[\\nlogT−1∏\\nt=1pθ(xt|xt+1)\\nq(xt|xt−1)]\\n(41)\\n=Eq(x1:T|x0)[logpθ(x0|x1)] +Eq(x1:T|x0)[\\nlogp(xT)\\nq(xT|xT−1)]\\n+Eq(x1:T|x0)[T−1∑\\nt=1logpθ(xt|xt+1)\\nq(xt|xt−1)]\\n(42)\\n=Eq(x1:T|x0)[logpθ(x0|x1)] +Eq(x1:T|x0)[\\nlogp(xT)\\nq(xT|xT−1)]\\n+T−1∑\\nt=1Eq(x1:T|x0)[\\nlogpθ(xt|xt+1)\\nq(xt|xt−1)]\\n(43)\\n=Eq(x1|x0)[logpθ(x0|x1)] +Eq(xT−1,xT|x0)[\\nlogp(xT)\\nq(xT|xT−1)]\\n+T−1∑\\nt=1Eq(xt−1,xt,xt+1|x0)[\\nlogpθ(xt|xt+1)\\nq(xt|xt−1)]\\n(44)\\n=Eq(x1|x0)[logpθ(x0|x1)]\\ued19\\ued18\\ued17\\ued1a\\nreconstruction term−Eq(xT−1|x0)[DKL(q(xT|xT−1)∥p(xT))]\\ued19 \\ued18\\ued17 \\ued1a\\nprior matching term\\n−T−1∑\\nt=1Eq(xt−1,xt+1|x0)[DKL(q(xt|xt−1)∥pθ(xt|xt+1))]\\ued19 \\ued18\\ued17 \\ued1a\\nconsistency term(45)\\nThe derived form of the ELBO can be interpreted in terms of its individual components:\\n1.Eq(x1|x0)[logpθ(x0|x1)]can be interpreted as a reconstruction term , predicting the log probability of\\nthe original data sample given the ﬁrst-step latent. This term also appears in a vanilla VAE, and can\\nbe trained similarly.\\n2.Eq(xT−1|x0)[DKL(q(xT|xT−1)∥p(xT))]is aprior matching term ; it is minimized when the ﬁnal latent\\ndistribution matches the Gaussian prior. This term requires no optimization, as it has no trainable\\nparameters; furthermore, as we have assumed a large enough Tsuch that the ﬁnal distribution is\\nGaussian, this term eﬀectively becomes zero.\\n3.Eq(xt−1,xt+1|x0)[DKL(q(xt|xt−1)∥pθ(xt|xt+1))]is aconsistency term ; it endeavors to make the distri-\\nbution atxtconsistent, from both forward and backward processes. That is, a denoising step from a\\nnoisier image should match the corresponding noising step from a cleaner image, for every intermediate\\ntimestep; this is reﬂected mathematically by the KL Divergence. This term is minimized when we train\\npθ(xt|xt+1)to match the Gaussian distribution q(xt|xt−1), which is deﬁned in Equation 31.\\n8', metadata={'source': 'diffusion_models.pdf', 'page': 7}),\n",
       " Document(page_content='Figure 4: Under our ﬁrst derivation, a VDM can be optimized by ensuring that for every intermediate xt,\\nthe posterior from the latent above it pθ(xt|xt+1)matches the Gaussian corruption of the latent before it\\nq(xt|xt−1). In this ﬁgure, for each intermediate xt, we minimize the diﬀerence between the distributions\\nrepresented by the pink and green arrows.\\nVisually, this interpretation of the ELBO is depicted in Figure 4. The cost of optimizing a VDM is primarily\\ndominated by the third term, since we must optimize over all timesteps t.\\nUnder this derivation, all terms of the ELBO are computed as expectations, and can therefore be approxi-\\nmated using Monte Carlo estimates. However, actually optimizing the ELBO using the terms we just derived\\nmight be suboptimal; because the consistency term is computed as an expectation over two random variables\\n{xt−1,xt+1}for every timestep, the variance of its Monte Carlo estimate could potentially be higher than a\\nterm that is estimated using only one random variable per timestep. As it is computed by summing up T−1\\nconsistency terms, the ﬁnal estimated value of the ELBO may have high variance for large Tvalues.\\nLet us instead try to derive a form for our ELBO where each term is computed as an expectation over only\\none random variable at a time. The key insight is that we can rewrite encoder transitions as q(xt|xt−1) =\\nq(xt|xt−1,x0), wheretheextraconditioningtermissuperﬂuousduetotheMarkovproperty. Then, according\\nto Bayes rule, we can rewrite each transition as:\\nq(xt|xt−1,x0) =q(xt−1|xt,x0)q(xt|x0)\\nq(xt−1|x0)(46)\\nArmed with this new equation, we can retry the derivation resuming from the ELBO in Equation 37:\\nlogp(x)≥Eq(x1:T|x0)[\\nlogp(x0:T)\\nq(x1:T|x0)]\\n(47)\\n=Eq(x1:T|x0)[\\nlogp(xT)∏T\\nt=1pθ(xt−1|xt)\\n∏T\\nt=1q(xt|xt−1)]\\n(48)\\n=Eq(x1:T|x0)[\\nlogp(xT)pθ(x0|x1)∏T\\nt=2pθ(xt−1|xt)\\nq(x1|x0)∏T\\nt=2q(xt|xt−1)]\\n(49)\\n=Eq(x1:T|x0)[\\nlogp(xT)pθ(x0|x1)∏T\\nt=2pθ(xt−1|xt)\\nq(x1|x0)∏T\\nt=2q(xt|xt−1,x0)]\\n(50)\\n=Eq(x1:T|x0)[\\nlogpθ(xT)pθ(x0|x1)\\nq(x1|x0)+ logT∏\\nt=2pθ(xt−1|xt)\\nq(xt|xt−1,x0)]\\n(51)\\n=Eq(x1:T|x0)\\uf8ee\\n\\uf8f0logp(xT)pθ(x0|x1)\\nq(x1|x0)+ logT∏\\nt=2pθ(xt−1|xt)\\nq(xt−1|xt,x0)q(xt|x0)\\nq(xt−1|x0)\\uf8f9\\n\\uf8fb (52)\\n9', metadata={'source': 'diffusion_models.pdf', 'page': 8}),\n",
       " Document(page_content='=Eq(x1:T|x0)\\uf8ee\\n\\uf8f0logp(xT)pθ(x0|x1)\\nq(x1|x0)+ logT∏\\nt=2pθ(xt−1|xt)\\nq(xt−1|xt,x0)\\x18\\x18\\x18\\x18q(xt|x0)\\n(((((q(xt−1|x0)\\uf8f9\\n\\uf8fb (53)\\n=Eq(x1:T|x0)[\\nlogp(xT)pθ(x0|x1)\\n\\x18\\x18\\x18\\x18q(x1|x0)+ log\\x18\\x18\\x18\\x18q(x1|x0)\\nq(xT|x0)+ logT∏\\nt=2pθ(xt−1|xt)\\nq(xt−1|xt,x0)]\\n(54)\\n=Eq(x1:T|x0)[\\nlogp(xT)pθ(x0|x1)\\nq(xT|x0)+T∑\\nt=2logpθ(xt−1|xt)\\nq(xt−1|xt,x0)]\\n(55)\\n=Eq(x1:T|x0)[logpθ(x0|x1)] +Eq(x1:T|x0)[\\nlogp(xT)\\nq(xT|x0)]\\n+T∑\\nt=2Eq(x1:T|x0)[\\nlogpθ(xt−1|xt)\\nq(xt−1|xt,x0)]\\n(56)\\n=Eq(x1|x0)[logpθ(x0|x1)] +Eq(xT|x0)[\\nlogp(xT)\\nq(xT|x0)]\\n+T∑\\nt=2Eq(xt,xt−1|x0)[\\nlogpθ(xt−1|xt)\\nq(xt−1|xt,x0)]\\n(57)\\n=Eq(x1|x0)[logpθ(x0|x1)]\\ued19\\ued18\\ued17\\ued1a\\nreconstruction term−DKL(q(xT|x0)∥p(xT))\\ued19\\ued18\\ued17\\ued1a\\nprior matching term−T∑\\nt=2Eq(xt|x0)[DKL(q(xt−1|xt,x0)∥pθ(xt−1|xt))]\\ued19 \\ued18\\ued17 \\ued1a\\ndenoising matching term(58)\\nWe have therefore successfully derived an interpretation for the ELBO that can be estimated with lower\\nvariance, as each term is computed as an expectation of at most one random variable at a time. This\\nformulation also has an elegant interpretation, which is revealed when inspecting each individual term:\\n1.Eq(x1|x0)[logpθ(x0|x1)]can be interpreted as a reconstruction term; like its analogue in the ELBO of\\na vanilla VAE, this term can be approximated and optimized using a Monte Carlo estimate.\\n2.DKL(q(xT|x0)∥p(xT))represents how close the distribution of the ﬁnal noisiﬁed input is to the stan-\\ndard Gaussian prior. It has no trainable parameters, and is also equal to zero under our assumptions.\\n3.Eq(xt|x0)[DKL(q(xt−1|xt,x0)∥pθ(xt−1|xt))]is adenoising matching term . We learn desired denoising\\ntransition step pθ(xt−1|xt)as an approximation to tractable, ground-truth denoising transition step\\nq(xt−1|xt,x0). Theq(xt−1|xt,x0)transition step can act as a ground-truth signal, since it deﬁnes\\nhow to denoise a noisy image xtwith access to what the ﬁnal, completely denoised image x0should\\nbe. This term is therefore minimized when the two denoising steps match as closely as possible, as\\nmeasured by their KL Divergence.\\nAs a side note, one observes that in the process of both ELBO derivations (Equation 45 and Equation 58),\\nonly the Markov assumption is used; as a result these formulae will hold true for any arbitrary Markovian\\nHVAE. Furthermore, when we set T= 1, both of the ELBO interpretations for a VDM exactly recreate the\\nELBO equation of a vanilla VAE, as written in Equation 19.\\nInthisderivationoftheELBO,thebulkoftheoptimizationcostonceagainliesinthesummationterm, which\\ndominates the reconstruction term. Whereas each KL Divergence term DKL(q(xt−1|xt,x0)∥pθ(xt−1|xt))\\nis diﬃcult to minimize for arbitrary posteriors in arbitrarily complex Markovian HVAEs due to the added\\ncomplexity of simultaneously learning the encoder, in a VDM we can leverage the Gaussian transition\\nassumption to make optimization tractable. By Bayes rule, we have:\\nq(xt−1|xt,x0) =q(xt|xt−1,x0)q(xt−1|x0)\\nq(xt|x0)\\nAs we already know that q(xt|xt−1,x0) =q(xt|xt−1) =N(xt;√αtxt−1,(1−αt)I)from our assumption re-\\ngarding encoder transitions (Equation 31), what remains is deriving for the forms of q(xt|x0)andq(xt−1|x0).\\nFortunately, these are also made tractable by utilizing the fact that the encoder transitions of a VDM are\\nlinear Gaussian models. Recall that under the reparameterization trick, samples xt∼q(xt|xt−1)can be\\nrewritten as:\\nxt=√αtxt−1+√\\n1−αtϵwithϵ∼N(ϵ;0,I) (59)\\nand that similarly, samples xt−1∼q(xt−1|xt−2)can be rewritten as:\\nxt−1=√αt−1xt−2+√\\n1−αt−1ϵwithϵ∼N(ϵ;0,I) (60)\\n10', metadata={'source': 'diffusion_models.pdf', 'page': 9}),\n",
       " Document(page_content='Figure 5: Depicted is an alternate, lower-variance method to optimize a VDM; we compute the form of\\nground-truth denoising step q(xt−1|xt,x0)using Bayes rule, and minimize its KL Divergence with our\\napproximate denoising step pθ(xt−1|xt). This is once again denoted visually by matching the distributions\\nrepresented by the green arrows with those of the pink arrows. Artistic liberty is at play here; in the full\\npicture, each pink arrow must also stem from x0, as it is also a conditioning term.\\nThen, theformof q(xt|x0)canberecursivelyderivedthroughrepeatedapplicationsofthereparameterization\\ntrick. Suppose that we have access to 2 Trandom noise variables {ϵ∗\\nt,ϵt}T\\nt=0iid∼N (ϵ;0,I). Then, for an\\narbitrary sample xt∼q(xt|x0), we can rewrite it as:\\nxt=√αtxt−1+√\\n1−αtϵ∗\\nt−1 (61)\\n=√αt(√αt−1xt−2+√\\n1−αt−1ϵ∗\\nt−2)\\n+√\\n1−αtϵ∗\\nt−1 (62)\\n=√αtαt−1xt−2+√\\nαt−αtαt−1ϵ∗\\nt−2+√\\n1−αtϵ∗\\nt−1 (63)\\n=√αtαt−1xt−2+√√\\nαt−αtαt−12+√\\n1−αt2ϵt−2 (64)\\n=√αtαt−1xt−2+√\\nαt−αtαt−1+ 1−αtϵt−2 (65)\\n=√αtαt−1xt−2+√\\n1−αtαt−1ϵt−2 (66)\\n=... (67)\\n=\\ued6a\\ued6b\\ued6b√t∏\\ni=1αix0+\\ued6a\\ued6b\\ued6b√1−t∏\\ni=1αiϵ0 (68)\\n=√¯αtx0+√\\n1−¯αtϵ0 (69)\\n∼N(xt;√¯αtx0,(1−¯αt)I) (70)\\nwhere in Equation 64 we have utilized the fact that the sum of two independent Gaussian random variables\\nremains a Gaussian with mean being the sum of the two means, and variance being the sum of the two\\nvariances. Interpreting√1−αtϵ∗\\nt−1as a sample from Gaussian N(0,(1−αt)I), and√αt−αtαt−1ϵ∗\\nt−2as\\na sample from Gaussian N(0,(αt−αtαt−1)I), we can then treat their sum as a random variable sampled\\nfrom GaussianN(0,(1−αt+αt−αtαt−1)I) =N(0,(1−αtαt−1)I). A sample from this distribution can\\nthen be represented using the reparameterization trick as√1−αtαt−1ϵt−2, as in Equation 66.\\n11', metadata={'source': 'diffusion_models.pdf', 'page': 10}),\n",
       " Document(page_content='We have therefore derived the Gaussian form of q(xt|x0). This derivation can be modiﬁed to also yield the\\nGaussian parameterization describing q(xt−1|x0). Now, knowing the forms of both q(xt|x0)andq(xt−1|x0),\\nwe can proceed to calculate the form of q(xt−1|xt,x0)by substituting into the Bayes rule expansion:\\nq(xt−1|xt,x0)=q(xt|xt−1,x0)q(xt−1|x0)\\nq(xt|x0)(71)\\n=N(xt;√αtxt−1,(1−αt)I)N(xt−1;√¯αt−1x0,(1−¯αt−1)I)\\nN(xt;√¯αtx0,(1−¯αt)I)(72)\\n∝exp{\\n−[(xt−√αtxt−1)2\\n2(1−αt)+(xt−1−√¯αt−1x0)2\\n2(1−¯αt−1)−(xt−√¯αtx0)2\\n2(1−¯αt)]}\\n(73)\\n=exp{\\n−1\\n2[(xt−√αtxt−1)2\\n1−αt+(xt−1−√¯αt−1x0)2\\n1−¯αt−1−(xt−√¯αtx0)2\\n1−¯αt]}\\n(74)\\n=exp{\\n−1\\n2[(−2√αtxtxt−1+αtx2\\nt−1)\\n1−αt+(x2\\nt−1−2√¯αt−1xt−1x0)\\n1−¯αt−1+C(xt,x0)]}\\n(75)\\n∝exp{\\n−1\\n2[\\n−2√αtxtxt−1\\n1−αt+αtx2\\nt−1\\n1−αt+x2\\nt−1\\n1−¯αt−1−2√¯αt−1xt−1x0\\n1−¯αt−1]}\\n(76)\\n=exp{\\n−1\\n2[\\n(αt\\n1−αt+1\\n1−¯αt−1)x2\\nt−1−2(√αtxt\\n1−αt+√¯αt−1x0\\n1−¯αt−1)\\nxt−1]}\\n(77)\\n=exp{\\n−1\\n2[αt(1−¯αt−1) + 1−αt\\n(1−αt)(1−¯αt−1)x2\\nt−1−2(√αtxt\\n1−αt+√¯αt−1x0\\n1−¯αt−1)\\nxt−1]}\\n(78)\\n=exp{\\n−1\\n2[αt−¯αt+ 1−αt\\n(1−αt)(1−¯αt−1)x2\\nt−1−2(√αtxt\\n1−αt+√¯αt−1x0\\n1−¯αt−1)\\nxt−1]}\\n(79)\\n=exp{\\n−1\\n2[1−¯αt\\n(1−αt)(1−¯αt−1)x2\\nt−1−2(√αtxt\\n1−αt+√¯αt−1x0\\n1−¯αt−1)\\nxt−1]}\\n(80)\\n=exp\\uf8f1\\n\\uf8f2\\n\\uf8f3−1\\n2(1−¯αt\\n(1−αt)(1−¯αt−1))\\uf8ee\\n\\uf8f0x2\\nt−1−2(√αtxt\\n1−αt+√¯αt−1x0\\n1−¯αt−1)\\n1−¯αt\\n(1−αt)(1−¯αt−1)xt−1\\uf8f9\\n\\uf8fb\\uf8fc\\n\\uf8fd\\n\\uf8fe(81)\\n=exp\\uf8f1\\n\\uf8f2\\n\\uf8f3−1\\n2(1−¯αt\\n(1−αt)(1−¯αt−1))\\uf8ee\\n\\uf8f0x2\\nt−1−2(√αtxt\\n1−αt+√¯αt−1x0\\n1−¯αt−1)\\n(1−αt)(1−¯αt−1)\\n1−¯αtxt−1\\uf8f9\\n\\uf8fb\\uf8fc\\n\\uf8fd\\n\\uf8fe(82)\\n=exp{\\n−1\\n2(\\n1\\n(1−αt)(1−¯αt−1)\\n1−¯αt)[\\nx2\\nt−1−2√αt(1−¯αt−1)xt+√¯αt−1(1−αt)x0\\n1−¯αtxt−1]}\\n(83)\\n∝N(xt−1;√αt(1−¯αt−1)xt+√¯αt−1(1−αt)x0\\n1−¯αt\\ued19 \\ued18\\ued17 \\ued1a\\nµq(xt,x0),(1−αt)(1−¯αt−1)\\n1−¯αtI\\n\\ued19\\ued18\\ued17\\ued1a\\nΣq(t)) (84)\\nwhere in Equation 75, C(xt,x0)is a constant term with respect to xt−1computed as a combination of only\\nxt,x0, andαvalues; this term is implicitly returned in Equation 84 to complete the square.\\nWe have therefore shown that at each step, xt−1∼q(xt−1|xt,x0)is normally distributed, with mean\\nµq(xt,x0)that is a function of xtandx0, and variance Σq(t)as a function of αcoeﬃcients. These\\nαcoeﬃcients are known and ﬁxed at each timestep; they are either set permanently when modeled as\\nhyperparameters, ortreatedasthecurrentinferenceoutputofanetworkthatseekstomodelthem. Following\\nEquation 84, we can rewrite our variance equation as Σq(t) =σ2\\nq(t)I, where:\\nσ2\\nq(t) =(1−αt)(1−¯αt−1)\\n1−¯αt(85)\\nIn order to match approximate denoising transition step pθ(xt−1|xt)to ground-truth denoising transition\\nstepq(xt−1|xt,x0)as closely as possible, we can also model it as a Gaussian. Furthermore, as all αterms\\nare known to be frozen at each timestep, we can immediately construct the variance of the approximate\\ndenoising transition step to also be Σq(t) =σ2\\nq(t)I. We must parameterize its mean µθ(xt,t)as a function\\nofxt, however, since pθ(xt−1|xt)does not condition on x0.\\n12', metadata={'source': 'diffusion_models.pdf', 'page': 11}),\n",
       " Document(page_content='Recall that the KL Divergence between two Gaussian distributions is:\\nDKL(N(x;µx,Σx)∥N(y;µy,Σy)) =1\\n2[\\nlog|Σy|\\n|Σx|−d+tr(Σ−1\\nyΣx) + (µy−µx)TΣ−1\\ny(µy−µx)]\\n(86)\\nIn our case, where we can set the variances of the two Gaussians to match exactly, optimizing the KL\\nDivergence term reduces to minimizing the diﬀerence between the means of the two distributions:\\narg min\\nθDKL(q(xt−1|xt,x0)∥pθ(xt−1|xt))\\n= arg min\\nθDKL(N(xt−1;µq,Σq(t))∥N(xt−1;µθ,Σq(t))) (87)\\n= arg min\\nθ1\\n2[\\nlog|Σq(t)|\\n|Σq(t)|−d+tr(Σq(t)−1Σq(t)) + (µθ−µq)TΣq(t)−1(µθ−µq)]\\n(88)\\n= arg min\\nθ1\\n2[\\nlog 1−d+d+ (µθ−µq)TΣq(t)−1(µθ−µq)]\\n(89)\\n= arg min\\nθ1\\n2[\\n(µθ−µq)TΣq(t)−1(µθ−µq)]\\n(90)\\n= arg min\\nθ1\\n2[\\n(µθ−µq)T(\\nσ2\\nq(t)I)−1(µθ−µq)]\\n(91)\\n= arg min\\nθ1\\n2σ2q(t)[\\n∥µθ−µq∥2\\n2]\\n(92)\\nwhere we have written µqas shorthand for µq(xt,x0), andµθas shorthand for µθ(xt,t)for brevity. In\\nother words, we want to optimize a µθ(xt,t)that matches µq(xt,x0), which from our derived Equation 84,\\ntakes the form:\\nµq(xt,x0) =√αt(1−¯αt−1)xt+√¯αt−1(1−αt)x0\\n1−¯αt(93)\\nAsµθ(xt,t)also conditions on xt, we can match µq(xt,x0)closely by setting it to the following form:\\nµθ(xt,t) =√αt(1−¯αt−1)xt+√¯αt−1(1−αt)ˆxθ(xt,t)\\n1−¯αt(94)\\nwhere ˆxθ(xt,t)is parameterized by a neural network that seeks to predict x0from noisy image xtand time\\nindext. Then, the optimization problem simpliﬁes to:\\narg min\\nθDKL(q(xt−1|xt,x0)∥pθ(xt−1|xt))\\n=arg min\\nθDKL(N(xt−1;µq,Σq(t))∥N(xt−1;µθ,Σq(t))) (95)\\n=arg min\\nθ1\\n2σ2q(t)[\\ued79\\ued79\\ued79\\ued79√αt(1−¯αt−1)xt+√¯αt−1(1−αt)ˆxθ(xt,t)\\n1−¯αt−√αt(1−¯αt−1)xt+√¯αt−1(1−αt)x0\\n1−¯αt\\ued79\\ued79\\ued79\\ued792\\n2]\\n(96)\\n=arg min\\nθ1\\n2σ2q(t)[\\ued79\\ued79\\ued79\\ued79√¯αt−1(1−αt)ˆxθ(xt,t)\\n1−¯αt−√¯αt−1(1−αt)x0\\n1−¯αt\\ued79\\ued79\\ued79\\ued792\\n2]\\n(97)\\n=arg min\\nθ1\\n2σ2q(t)[\\ued79\\ued79\\ued79\\ued79√¯αt−1(1−αt)\\n1−¯αt(ˆxθ(xt,t)−x0)\\ued79\\ued79\\ued79\\ued792\\n2]\\n(98)\\n=arg min\\nθ1\\n2σ2q(t)¯αt−1(1−αt)2\\n(1−¯αt)2[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n(99)\\nTherefore, optimizing a VDM boils down to learning a neural network to predict the original ground truth\\nimage from an arbitrarily noisiﬁed version of it [5]. Furthermore, minimizing the summation term of our\\nderived ELBO objective (Equation 58) across all noise levels can be approximated by minimizing the expec-\\ntation over all timesteps:\\narg min\\nθEt∼U{2,T}[\\nEq(xt|x0)[DKL(q(xt−1|xt,x0)∥pθ(xt−1|xt))]]\\n(100)\\nwhich can then be optimized using stochastic samples over timesteps.\\n13', metadata={'source': 'diffusion_models.pdf', 'page': 12}),\n",
       " Document(page_content='Learning Diﬀusion Noise Parameters\\nLet us investigate how the noise parameters of a VDM can be jointly learned. One potential approach is to\\nmodelαtusing a neural network ˆαη(t)with parameters η. However, this is ineﬃcient as inference must be\\nperformedmultipletimesateachtimestep ttocompute ¯αt. Whereascachingcanmitigatethiscomputational\\ncost, we can also derive an alternate way to learn the diﬀusion noise parameters. By substituting our variance\\nequation from Equation 85 into our derived per-timestep objective in Equation 99, we can reduce:\\n1\\n2σ2q(t)¯αt−1(1−αt)2\\n(1−¯αt)2[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n=1\\n2(1−αt)(1−¯αt−1)\\n1−¯αt¯αt−1(1−αt)2\\n(1−¯αt)2[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n(101)\\n=1\\n21−¯αt\\n(1−αt)(1−¯αt−1)¯αt−1(1−αt)2\\n(1−¯αt)2[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n(102)\\n=1\\n2¯αt−1(1−αt)\\n(1−¯αt−1)(1−¯αt)[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n(103)\\n=1\\n2¯αt−1−¯αt\\n(1−¯αt−1)(1−¯αt)[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n(104)\\n=1\\n2¯αt−1−¯αt−1¯αt+ ¯αt−1¯αt−¯αt\\n(1−¯αt−1)(1−¯αt)[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n(105)\\n=1\\n2¯αt−1(1−¯αt)−¯αt(1−¯αt−1)\\n(1−¯αt−1)(1−¯αt)[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n(106)\\n=1\\n2(¯αt−1(1−¯αt)\\n(1−¯αt−1)(1−¯αt)−¯αt(1−¯αt−1)\\n(1−¯αt−1)(1−¯αt))[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n(107)\\n=1\\n2(¯αt−1\\n1−¯αt−1−¯αt\\n1−¯αt)[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n(108)\\nRecall from Equation 70 that q(xt|x0)is a Gaussian of form N(xt;√¯αtx0,(1−¯αt)I). Then, following the\\ndeﬁnition of the signal-to-noise ratio (SNR) as SNR =µ2\\nσ2, we can write the SNR at each timestep tas:\\nSNR(t) =¯αt\\n1−¯αt(109)\\nThen, our derived Equation 108 (and Equation 99) can be simpliﬁed as:\\n1\\n2σ2q(t)¯αt−1(1−αt)2\\n(1−¯αt)2[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n=1\\n2(SNR(t−1)−SNR(t))[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n(110)\\nAsthenameimplies,theSNRrepresentstheratiobetweentheoriginalsignalandtheamountofnoisepresent;\\na higher SNR represents more signal and a lower SNR represents more noise. In a diﬀusion model, we require\\nthe SNR to monotonically decrease as timestep tincreases; this formalizes the notion that perturbed input\\nxtbecomes increasingly noisy over time, until it becomes identical to a standard Gaussian at t=T.\\nFollowing the simpliﬁcation of the objective in Equation 110, we can directly parameterize the SNR at each\\ntimestep using a neural network, and learn it jointly along with the diﬀusion model. As the SNR must\\nmonotonically decrease over time, we can represent it as:\\nSNR(t) =exp(−ωη(t)) (111)\\nwhereωη(t)is modeled as a monotonically increasing neural network with parameters η. Negating ωη(t)\\nresults in a monotonically decreasing function, whereas the exponential forces the resulting term to be\\npositive. Note that the objective in Equation 100 must now optimize over ηas well. By combining our\\nparameterization of SNR in Equation 111 with our deﬁnition of SNR in Equation 109, we can also explicitly\\nderive elegant forms for the value of ¯αtas well as for the value of 1−¯αt:\\n¯αt\\n1−¯αt=exp(−ωη(t)) (112)\\n∴¯αt=sigmoid (−ωη(t)) (113)\\n∴1−¯αt=sigmoid (ωη(t)) (114)\\nThese terms are necessary for a variety of computations; for example, during optimization, they are used to\\ncreate arbitrarily noisy xtfrom inputx0using the reparameterization trick, as derived in Equation 69.\\n14', metadata={'source': 'diffusion_models.pdf', 'page': 13}),\n",
       " Document(page_content='Three Equivalent Interpretations\\nAs we previously proved, a Variational Diﬀusion Model can be trained by simply learning a neural network\\nto predict the original natural image x0from an arbitrary noised version xtand its time index t. However,\\nx0has two other equivalent parameterizations, which leads to two further interpretations for a VDM.\\nFirstly, wecanutilizethereparameterizationtrick. Inourderivationoftheformof q(xt|x0), wecanrearrange\\nEquation 69 to show that:\\nx0=xt−√1−¯αtϵ0√¯αt(115)\\nPluggingthisintoourpreviouslyderivedtruedenoisingtransitionmean µq(xt,x0), wecanrederiveas:\\nµq(xt,x0) =√αt(1−¯αt−1)xt+√¯αt−1(1−αt)x0\\n1−¯αt(116)\\n=√αt(1−¯αt−1)xt+√¯αt−1(1−αt)xt−√1−¯αtϵ0√¯αt\\n1−¯αt(117)\\n=√αt(1−¯αt−1)xt+ (1−αt)xt−√1−¯αtϵ0√αt\\n1−¯αt(118)\\n=√αt(1−¯αt−1)xt\\n1−¯αt+(1−αt)xt\\n(1−¯αt)√αt−(1−αt)√1−¯αtϵ0\\n(1−¯αt)√αt(119)\\n=(√αt(1−¯αt−1)\\n1−¯αt+1−αt\\n(1−¯αt)√αt)\\nxt−(1−αt)√1−¯αt\\n(1−¯αt)√αtϵ0 (120)\\n=(αt(1−¯αt−1)\\n(1−¯αt)√αt+1−αt\\n(1−¯αt)√αt)\\nxt−1−αt√1−¯αt√αtϵ0 (121)\\n=αt−¯αt+ 1−αt\\n(1−¯αt)√αtxt−1−αt√1−¯αt√αtϵ0 (122)\\n=1−¯αt\\n(1−¯αt)√αtxt−1−αt√1−¯αt√αtϵ0 (123)\\n=1√αtxt−1−αt√1−¯αt√αtϵ0 (124)\\nTherefore, we can set our approximate denoising transition mean µθ(xt,t)as:\\nµθ(xt,t) =1√αtxt−1−αt√1−¯αt√αtˆϵθ(xt,t) (125)\\nand the corresponding optimization problem becomes:\\narg min\\nθDKL(q(xt−1|xt,x0)∥pθ(xt−1|xt))\\n= arg min\\nθDKL(N(xt−1;µq,Σq(t))∥N(xt−1;µθ,Σq(t))) (126)\\n= arg min\\nθ1\\n2σ2q(t)[\\ued79\\ued79\\ued79\\ued791√αtxt−1−αt√1−¯αt√αtˆϵθ(xt,t)−1√αtxt+1−αt√1−¯αt√αtϵ0\\ued79\\ued79\\ued79\\ued792\\n2]\\n(127)\\n= arg min\\nθ1\\n2σ2q(t)[\\ued79\\ued79\\ued79\\ued791−αt√1−¯αt√αtϵ0−1−αt√1−¯αt√αtˆϵθ(xt,t)\\ued79\\ued79\\ued79\\ued792\\n2]\\n(128)\\n= arg min\\nθ1\\n2σ2q(t)[\\ued79\\ued79\\ued79\\ued791−αt√1−¯αt√αt(ϵ0−ˆϵθ(xt,t))\\ued79\\ued79\\ued79\\ued792\\n2]\\n(129)\\n= arg min\\nθ1\\n2σ2q(t)(1−αt)2\\n(1−¯αt)αt[\\n∥ϵ0−ˆϵθ(xt,t)∥2\\n2]\\n(130)\\n15', metadata={'source': 'diffusion_models.pdf', 'page': 14}),\n",
       " Document(page_content='Here, ˆϵθ(xt,t)is a neural network that learns to predict the source noise ϵ0∼N(ϵ;0,I)that determines xt\\nfromx0. We have therefore shown that learning a VDM by predicting the original image x0is equivalent to\\nlearning to predict the noise; empirically, however, some works have found that predicting the noise resulted\\nin better performance [5, 7].\\nTo derive the third common interpretation of Variational Diﬀusion Models, we appeal to Tweedie’s For-\\nmula [8]. In English, Tweedie’s Formula states that the true mean of an exponential family distribution,\\ngiven samples drawn from it, can be estimated by the maximum likelihood estimate of the samples (aka em-\\npirical mean) plus some correction term involving the score of the estimate. In the case of just one observed\\nsample, the empirical mean is just the sample itself. It is commonly used to mitigate sample bias; if observed\\nsamples all lie on one end of the underlying distribution, then the negative score becomes large and corrects\\nthe naive maximum likelihood estimate of the samples towards the true mean.\\nMathematically, for a Gaussian variable z∼N(z;µz,Σz), Tweedie’s Formula states that:\\nE[µz|z] =z+Σz∇zlogp(z)\\nIn this case, we apply it to predict the true posterior mean of xtgiven its samples. From Equation 70, we\\nknow that:\\nq(xt|x0) =N(xt;√¯αtx0,(1−¯αt)I)\\nThen, by Tweedie’s Formula, we have:\\nE[µxt|xt] =xt+ (1−¯αt)∇xtlogp(xt) (131)\\nwhere we write∇xtlogp(xt)as∇logp(xt)for notational simplicity. According to Tweedie’s Formula, the\\nbest estimate for the true mean that xtis generated from, µxt=√¯αtx0, is deﬁned as:\\n√¯αtx0=xt+ (1−¯αt)∇logp(xt) (132)\\n∴x0=xt+ (1−¯αt)∇logp(xt)√¯αt(133)\\nThen, we can plug Equation 133 into our ground-truth denoising transition mean µq(xt,x0)once again and\\nderive a new form:\\nµq(xt,x0) =√αt(1−¯αt−1)xt+√¯αt−1(1−αt)x0\\n1−¯αt(134)\\n=√αt(1−¯αt−1)xt+√¯αt−1(1−αt)xt+(1−¯αt)∇logp(xt)√¯αt\\n1−¯αt(135)\\n=√αt(1−¯αt−1)xt+ (1−αt)xt+(1−¯αt)∇logp(xt)√αt\\n1−¯αt(136)\\n=√αt(1−¯αt−1)xt\\n1−¯αt+(1−αt)xt\\n(1−¯αt)√αt+(1−αt)(1−¯αt)∇logp(xt)\\n(1−¯αt)√αt(137)\\n=(√αt(1−¯αt−1)\\n1−¯αt+1−αt\\n(1−¯αt)√αt)\\nxt+1−αt√αt∇logp(xt) (138)\\n=(αt(1−¯αt−1)\\n(1−¯αt)√αt+1−αt\\n(1−¯αt)√αt)\\nxt+1−αt√αt∇logp(xt) (139)\\n=αt−¯αt+ 1−αt\\n(1−¯αt)√αtxt+1−αt√αt∇logp(xt) (140)\\n=1−¯αt\\n(1−¯αt)√αtxt+1−αt√αt∇logp(xt) (141)\\n=1√αtxt+1−αt√αt∇logp(xt) (142)\\n16', metadata={'source': 'diffusion_models.pdf', 'page': 15}),\n",
       " Document(page_content='Therefore, we can also set our approximate denoising transition mean µθ(xt,t)as:\\nµθ(xt,t) =1√αtxt+1−αt√αtsθ(xt,t) (143)\\nand the corresponding optimization problem becomes:\\narg min\\nθDKL(q(xt−1|xt,x0)∥pθ(xt−1|xt))\\n= arg min\\nθDKL(N(xt−1;µq,Σq(t))∥N(xt−1;µθ,Σq(t))) (144)\\n= arg min\\nθ1\\n2σ2q(t)[\\ued79\\ued79\\ued79\\ued791√αtxt+1−αt√αtsθ(xt,t)−1√αtxt−1−αt√αt∇logp(xt)\\ued79\\ued79\\ued79\\ued792\\n2]\\n(145)\\n= arg min\\nθ1\\n2σ2q(t)[\\ued79\\ued79\\ued79\\ued791−αt√αtsθ(xt,t)−1−αt√αt∇logp(xt)\\ued79\\ued79\\ued79\\ued792\\n2]\\n(146)\\n= arg min\\nθ1\\n2σ2q(t)[\\ued79\\ued79\\ued79\\ued791−αt√αt(sθ(xt,t)−∇logp(xt))\\ued79\\ued79\\ued79\\ued792\\n2]\\n(147)\\n= arg min\\nθ1\\n2σ2q(t)(1−αt)2\\nαt[\\n∥sθ(xt,t)−∇logp(xt)∥2\\n2]\\n(148)\\nHere,sθ(xt,t)is a neural network that learns to predict the score function ∇xtlogp(xt), which is the\\ngradient ofxtin data space, for any arbitrary noise level t.\\nThe astute reader will notice that the score function ∇logp(xt)looks remarkably similar in form to the\\nsource noise ϵ0. This can be shown explicitly by combining Tweedie’s Formula (Equation 133) with the\\nreparameterization trick (Equation 115):\\nx0=xt+ (1−¯αt)∇logp(xt)√¯αt=xt−√1−¯αtϵ0√¯αt(149)\\n∴(1−¯αt)∇logp(xt) =−√\\n1−¯αtϵ0 (150)\\n∇logp(xt) =−1√1−¯αtϵ0 (151)\\nAs it turns out, the two terms are oﬀ by a constant factor that scales with time! The score function measures\\nhow to move in data space to maximize the log probability; intuitively, since the source noise is added to\\na natural image to corrupt it, moving in its opposite direction \"denoises\" the image and would be the best\\nupdate to increase the subsequent log probability. Our mathematical proof justiﬁes this intuition; we have\\nexplicitly shown that learning to model the score function is equivalent to modeling the negative of the source\\nnoise (up to a scaling factor).\\nWe have therefore derived three equivalent objectives to optimize a VDM: learning a neural network to\\npredict the original image x0, the source noise ϵ0, or the score of the image at an arbitrary noise level\\n∇logp(xt). The VDM can be scalably trained by stochastically sampling timesteps tand minimizing the\\nnorm of the prediction with the ground truth target.\\nScore-based Generative Models\\nWe have shown that a Variational Diﬀusion Model can be learned simply by optimizing a neural network\\nsθ(xt,t)to predict the score function ∇logp(xt). However, in our derivation, the score term arrived from\\nan application of Tweedie’s Formula; this doesn’t necessarily provide us with great intuition or insight into\\nwhat exactly the score function is or why it is worth modeling. Fortunately, we can look to another class of\\ngenerative models, Score-based Generative Models [9, 10, 11], for exactly this intuition. As it turns out, we\\ncan show that the VDM formulation we have previously derived has an equivalent Score-based Generative\\nModeling formulation, allowing us to ﬂexibly switch between these two interpretations at will.\\n17', metadata={'source': 'diffusion_models.pdf', 'page': 16}),\n",
       " Document(page_content='Figure 6: Visualization of three random sampling trajectories generated with Langevin dynamics, all starting\\nfromthesameinitializationpoint, foraMixtureofGaussians. Theleftﬁgureplotsthesesamplingtrajectories\\non a three-dimensional contour, while the right ﬁgure plots the sampling trajectories against the ground-\\ntruth score function. From the same initialization point, we are able to generate samples from diﬀerent\\nmodes due to the stochastic noise term in the Langevin dynamics sampling procedure; without it, sampling\\nfrom a ﬁxed point would always deterministically follow the score to the same mode every trial.\\nTo begin to understand why optimizing a score function makes sense, we take a detour and revisit energy-\\nbased models [12, 13]. Arbitrarily ﬂexible probability distributions can be written in the form:\\npθ(x) =1\\nZθe−fθ(x)(152)\\nwherefθ(x)is an arbitrarily ﬂexible, parameterizable function called the energy function, often modeled by\\na neural network, and Zθis a normalizing constant to ensure that∫\\npθ(x)dx= 1. One way to learn such\\na distribution is maximum likelihood; however, this requires tractably computing the normalizing constant\\nZθ=∫\\ne−fθ(x)dx, which may not be possible for complex fθ(x)functions.\\nOne way to avoid calculating or modeling the normalization constant is by using a neural network sθ(x)to\\nlearn the score function ∇logp(x)of distribution p(x)instead. This is motivated by the observation that\\ntaking the derivative of the log of both sides of Equation 152 yields:\\n∇xlogpθ(x) =∇xlog(1\\nZθe−fθ(x)) (153)\\n=∇xlog1\\nZθ+∇xloge−fθ(x)(154)\\n=−∇xfθ(x) (155)\\n≈sθ(x) (156)\\nwhichcanbefreelyrepresentedasaneuralnetworkwithoutinvolvinganynormalizationconstants. Thescore\\nmodel can be optimized by minimizing the Fisher Divergence with the ground truth score function:\\nEp(x)[\\n∥sθ(x)−∇logp(x)∥2\\n2]\\n(157)\\nWhat does the score function represent? For every x, taking the gradient of its log likelihood with respect\\ntoxessentially describes what direction in data space to move in order to further increase its likelihood.\\n18', metadata={'source': 'diffusion_models.pdf', 'page': 17}),\n",
       " Document(page_content='Intuitively, then, the score function deﬁnes a vector ﬁeld over the entire space that data xinhabits, pointing\\ntowards the modes. Visually, this is depicted in the right plot of Figure 6. Then, by learning the score\\nfunction of the true data distribution, we can generate samples by starting at any arbitrary point in the\\nsame space and iteratively following the score until a mode is reached. This sampling procedure is known\\nas Langevin dynamics, and is mathematically described as:\\nxi+1←xi+c∇logp(xi) +√\\n2cϵ, i= 0,1,...,K (158)\\nwherex0is randomly sampled from a prior distribution (such as uniform), and ϵ∼N (ϵ;0,I)is an extra\\nnoise term to ensure that the generated samples do not always collapse onto a mode, but hover around it\\nfor diversity. Furthermore, because the learned score function is deterministic, sampling with a noise term\\ninvolved adds stochasticity to the generative process, allowing us to avoid deterministic trajectories. This is\\nparticularly useful when sampling is initialized from a position that lies between multiple modes. A visual\\ndepiction of Langevin dynamics sampling and the beneﬁts of the noise term is shown in Figure 6.\\nNote that the objective in Equation 157 relies on having access to the ground truth score function, which is\\nunavailable to us for complex distributions such as the one modeling natural images. Fortunately, alternative\\ntechniques known as score matching [14, 15, 16, 17] have been derived to minimize this Fisher divergence\\nwithout knowing the ground truth score, and can be optimized with stochastic gradient descent.\\nCollectively, learning to represent a distribution as a score function and using it to generate samples through\\nMarkov Chain Monte Carlo techniques, such as Langevin dynamics, is known as Score-based Generative\\nModeling [9, 10, 11].\\nThere are three main problems with vanilla score matching, as detailed by Song and Ermon [9]. Firstly, the\\nscore function is ill-deﬁned when xlies on a low-dimensional manifold in a high-dimensional space. This can\\nbe seen mathematically; all points not on the low-dimensional manifold would have probability zero, the log\\nof which is undeﬁned. This is particularly inconvenient when trying to learn a generative model over natural\\nimages, which is known to lie on a low-dimensional manifold of the entire ambient space.\\nSecondly, the estimated score function trained via vanilla score matching will not be accurate in low density\\nregions. This is evident from the objective we minimize in Equation 157. Because it is an expectation over\\np(x), and explicitly trained on samples from it, the model will not receive an accurate learning signal for\\nrarely seen or unseen examples. This is problematic, since our sampling strategy involves starting from a\\nrandom location in the high-dimensional space, which is most likely random noise, and moving according to\\nthe learned score function. Since we are following a noisy or inaccurate score estimate, the ﬁnal generated\\nsamplesmaybesuboptimalaswell, orrequiremanymoreiterationstoconvergeonanaccurateoutput.\\nLastly, Langevin dynamics sampling may not mix, even if it is performed using the ground truth scores.\\nSuppose that the true data distribution is a mixture of two disjoint distributions:\\np(x) =c1p1(x) +c2p2(x) (159)\\nThen, when the score is computed, these mixing coeﬃcients are lost, since the log operation splits the\\ncoeﬃcient from the distribution and the gradient operation zeros it out. To visualize this, note that the\\nground truth score function shown in the right Figure 6 is agnostic of the diﬀerent weights between the three\\ndistributions; Langevin dynamics sampling from the depicted initialization point has a roughly equal chance\\nof arriving at each mode, despite the bottom right mode having a higher weight in the actual Mixture of\\nGaussians.\\nItturnsoutthatthesethreedrawbackscanbesimultaneouslyaddressedbyaddingmultiplelevelsofGaussian', metadata={'source': 'diffusion_models.pdf', 'page': 18}),\n",
       " Document(page_content='Gaussians.\\nItturnsoutthatthesethreedrawbackscanbesimultaneouslyaddressedbyaddingmultiplelevelsofGaussian\\nnoise to the data. Firstly, as the support of a Gaussian noise distribution is the entire space, a perturbed\\ndata sample will no longer be conﬁned to a low-dimensional manifold. Secondly, adding large Gaussian noise\\nwill increase the area each mode covers in the data distribution, adding more training signal in low density\\nregions. Lastly, adding multiple levels of Gaussian noise with increasing variance will result in intermediate\\ndistributions that respect the ground truth mixing coeﬃcients.\\n19', metadata={'source': 'diffusion_models.pdf', 'page': 18}),\n",
       " Document(page_content='Formally, we can choose a positive sequence of noise levels {σt}T\\nt=1and deﬁne a sequence of progressively\\nperturbed data distributions:\\npσt(xt) =∫\\np(x)N(xt;x,σ2\\ntI)dx (160)\\nThen, a neural network sθ(x,t)is learned using score matching to learn the score function for all noise levels\\nsimultaneously:\\narg min\\nθT∑\\nt=1λ(t)Epσt(xt)[\\n∥sθ(x,t)−∇logpσt(xt)∥2\\n2]\\n(161)\\nwhereλ(t)is a positive weighting function that conditions on noise level t. Note that this objective almost\\nexactly matches the objective derived in Equation 148 to train a Variational Diﬀusion Model. Furthermore,\\nthe authors propose annealed Langevin dynamics sampling as a generative procedure, in which samples are\\nproduced by running Langevin dynamics for each t=T,T−1,...,2,1in sequence. The initialization is chosen\\nfrom some ﬁxed prior (such as uniform), and each subsequent sampling step starts from the ﬁnal samples\\nof the previous simulation. Because the noise levels steadily decrease over timesteps t, and we reduce the\\nstep size over time, the samples eventually converge into a true mode. This is directly analogous to the\\nsampling procedure performed in the Markovian HVAE interpretation of a Variational Diﬀusion Model,\\nwhere a randomly initialized data vector is iteratively reﬁned over decreasing noise levels.\\nTherefore, we have established an explicit connection between Variational Diﬀusion Models and Score-based\\nGenerative Models, both in their training objectives and sampling procedures.\\nOne question is how to naturally generalize diﬀusion models to an inﬁnite number of timesteps. Under the\\nMarkovian HVAE view, this can be interpreted as extending the number of hierarchies to inﬁnity T→∞.\\nIt is clearer to represent this from the equivalent score-based generative model perspective; under an inﬁnite\\nnumber of noise scales, the perturbation of an image over continuous time can be represented as a stochastic\\nprocess, and therefore described by a stochastic diﬀerential equation (SDE). Sampling is then performed by\\nreversing the SDE, which naturally requires estimating the score function at each continuous-valued noise\\nlevel [10]. Diﬀerent parameterizations of the SDE essentially describe diﬀerent perturbation schemes over\\ntime, enabling ﬂexible modeling of the noising procedure [6].\\nGuidance\\nSo far, we have focused on modeling just the data distribution p(x). However, we are often also interested\\nin learning conditional distribution p(x|y), which would enable us to explicitly control the data we generate\\nthrough conditioning information y. This forms the backbone of image super-resolution models such as\\nCascaded Diﬀusion Models [18], as well as state-of-the-art image-text models such as DALL-E 2 [19] and\\nImagen [7].\\nAnaturalwaytoaddconditioninginformationissimplyalongsidethetimestepinformation, ateachiteration.\\nRecall our joint distribution from Equation 32:\\np(x0:T) =p(xT)T∏\\nt=1pθ(xt−1|xt)\\nThen, to turn this into a conditional diﬀusion model, we can simply add arbitrary conditioning information\\nyat each transition step as:\\np(x0:T|y) =p(xT)T∏\\nt=1pθ(xt−1|xt,y) (162)\\nFor example, ycould be a text encoding in image-text generation, or a low-resolution image to perform\\nsuper-resolution on. We are thus able to learn the core neural networks of a VDM as before, by predict-\\ningˆxθ(xt,t,y)≈x0,ˆϵθ(xt,t,y)≈ϵ0, orsθ(xt,t,y)≈∇ logp(xt|y)for each desired interpretation and\\nimplementation.\\n20', metadata={'source': 'diffusion_models.pdf', 'page': 19}),\n",
       " Document(page_content='A caveat of this vanilla formulation is that a conditional diﬀusion model trained in this way may potentially\\nlearn to ignore or downplay any given conditioning information. Guidance is therefore proposed as a way\\nto more explicitly control the amount of weight the model gives to the conditioning information, at the cost\\nof sample diversity. The two most popular forms of guidance are known as Classiﬁer Guidance [10, 20] and\\nClassiﬁer-Free Guidance [21].\\nClassiﬁer Guidance\\nLet us begin with the score-based formulation of a diﬀusion model, where our goal is to learn ∇logp(xt|y),\\nthe score of the conditional model, at arbitrary noise levels t. Recall that∇is shorthand for∇xtin the\\ninterest of brevity. By Bayes rule, we can derive the following equivalent form:\\n∇logp(xt|y) =∇log(p(xt)p(y|xt)\\np(y))\\n(163)\\n=∇logp(xt) +∇logp(y|xt)−∇logp(y) (164)\\n=∇logp(xt)\\ued19\\ued18\\ued17\\ued1a\\nunconditional score+∇logp(y|xt)\\ued19\\ued18\\ued17\\ued1a\\nadversarial gradient(165)\\nwhere we have leveraged the fact that the gradient of logp(y)with respect to xtis zero.\\nOur ﬁnal derived result can be interpreted as learning an unconditional score function combined with the\\nadversarial gradient of a classiﬁer p(y|xt). Therefore, in Classiﬁer Guidance [10, 20], the score of an uncon-\\nditional diﬀusion model is learned as previously derived, alongside a classiﬁer that takes in arbitrary noisy\\nxtand attempts to predict conditional information y. Then, during the sampling procedure, the overall\\nconditional score function used for annealed Langevin dynamics is computed as the sum of the unconditional\\nscore function and the adversarial gradient of the noisy classiﬁer.\\nIn order to introduce ﬁne-grained control to either encourage or discourage the model to consider the condi-\\ntioning information, Classiﬁer Guidance scales the adversarial gradient of the noisy classiﬁer by a γhyper-\\nparameter term. The score function learned under Classiﬁer Guidance can then be summarized as:\\n∇logp(xt|y) =∇logp(xt) +γ∇logp(y|xt) (166)\\nIntuitively, when γ= 0the conditional diﬀusion model learns to ignore the conditioning information entirely,\\nand whenγis large the conditional diﬀusion model learns to produce samples that heavily adhere to the\\nconditioning information. This would come at the cost of sample diversity, as it would only produce data\\nthat would be easy to regenerate the provided conditioning information from, even at noisy levels.\\nOne noted drawback of Classiﬁer Guidance is its reliance on a separately learned classiﬁer. Because the\\nclassiﬁer must handle arbitrarily noisy inputs, which most existing pretrained classiﬁcation models are not\\noptimized to do, it must be learned ad hoc alongside the diﬀusion model.\\nClassiﬁer-Free Guidance\\nIn Classiﬁer-Free Guidance [21], the authors ditch the training of a separate classiﬁer model in favor of\\nan unconditional diﬀusion model and a conditional diﬀusion model. To derive the score function under\\nClassiﬁer-Free Guidance, we can ﬁrst rearrange Equation 165 to show that:\\n∇logp(y|xt) =∇logp(xt|y)−∇logp(xt) (167)\\nThen, substituting this into Equation 166, we get:\\n∇logp(xt|y) =∇logp(xt) +γ(∇logp(xt|y)−∇logp(xt)) (168)\\n=∇logp(xt) +γ∇logp(xt|y)−γ∇logp(xt) (169)\\n=γ∇logp(xt|y)\\ued19\\ued18\\ued17\\ued1a\\nconditional score+ (1−γ)∇logp(xt)\\ued19\\ued18\\ued17\\ued1a\\nunconditional score(170)\\n21', metadata={'source': 'diffusion_models.pdf', 'page': 20}),\n",
       " Document(page_content='Once again, γis a term that controls how much our learned conditional model cares about the conditioning\\ninformation. When γ= 0, the learned conditional model completely ignores the conditioner and learns an\\nunconditional diﬀusion model. When γ= 1, the model explicitly learns the vanilla conditional distribution\\nwithout guidance. When γ > 1, the diﬀusion model not only prioritizes the conditional score function,\\nbut also moves in the direction away from the unconditional score function. In other words, it reduces the\\nprobability of generating samples that do not use conditioning information, in favor of the samples that\\nexplicitly do. This also has the eﬀect of decreasing sample diversity at the cost of generating samples that\\naccurately match the conditioning information.\\nBecause learning two separate diﬀusion models is expensive, we can learn both the conditional and uncon-\\nditional diﬀusion models together as a singular conditional model; the unconditional diﬀusion model can be\\nqueriedbyreplacing theconditioning information withﬁxed constant values, suchaszeros. Thisis essentially\\nperforming random dropout on the conditioning information. Classiﬁer-Free Guidance is elegant because\\nit enables us greater control over our conditional generation procedure while requiring nothing beyond the\\ntraining of a singular diﬀusion model.\\nClosing\\nAllowustorecapitulateourﬁndingsoverthecourseofourexplorations. First, wederiveVariationalDiﬀusion\\nModels as a special case of a Markovian Hierarchical Variational Autoencoder, where three key assumptions\\nenable tractable computation and scalable optimization of the ELBO. We then prove that optimizing a VDM\\nboils down to learning a neural network to predict one of three potential objectives: the original source image\\nfrom any arbitrary noisiﬁcation of it, the original source noise from any arbitrarily noisiﬁed image, or the\\nscore function of a noisiﬁed image at any arbitrary noise level. Then, we dive deeper into what it means to\\nlearn the score function, and connect it explicitly with the perspective of Score-based Generative Modeling.\\nLastly, we cover how to learn a conditional distribution using diﬀusion models.\\nIn summary, diﬀusion models have shown incredible capabilities as generative models; indeed, they power\\nthe current state-of-the-art models on text-conditioned image generation such as Imagen and DALL-E 2.\\nFurthermore, the mathematics that enable these models are exceedingly elegant. However, there still remain\\na few drawbacks to consider:\\n•It is unlikely that this is how we, as humans, naturally model and generate data; we do not generate\\nsamples as random noise that we iteratively denoise.\\n•The VDM does not produce interpretable latents. Whereas a VAE would hopefully learn a structured\\nlatent space through the optimization of its encoder, in a VDM the encoder at each timestep is already\\ngiven as a linear Gaussian model and cannot be optimized ﬂexibly. Therefore, the intermediate latents\\nare restricted as just noisy versions of the original input.\\n•The latents are restricted to the same dimensionality as the original input, further frustrating eﬀorts\\nto learn meaningful, compressed latent structure.\\n•Sampling is an expensive procedure, as multiple denoising steps must be run under both formulations.\\nRecall that one of the restrictions is that a large enough number of timesteps Tis chosen to ensure the\\nﬁnal latent is completely Gaussian noise; during sampling we must iterate over all these timesteps to\\ngenerate a sample.\\nAs a ﬁnal note, the success of diﬀusion models highlights the power of Hierarchical VAEs as a generative\\nmodel. We have shown that when we generalize to inﬁnitelatent hierarchies, even if the encoder is trivial\\nand the latent dimension is ﬁxed and Markovian transitions are assumed, we are still able to learn powerful\\nmodels of data. This suggests that further performance gains can be achieved in the case of general, deep', metadata={'source': 'diffusion_models.pdf', 'page': 21}),\n",
       " Document(page_content='models of data. This suggests that further performance gains can be achieved in the case of general, deep\\nHVAEs, wherecomplexencodersandsemanticallymeaningfullatentspacescanbepotentiallylearned.\\nAcknowledgments: I would like to acknowledge Josh Dillon, Yang Song, Durk Kingma, Ben Poole,\\nJonathan Ho, Yiding Jiang, Ting Chen, Jeremy Cohen, and Chen Sun for reviewing drafts of this work\\nand providing many helpful edits and comments. Thanks so much!\\n22', metadata={'source': 'diffusion_models.pdf', 'page': 21}),\n",
       " Document(page_content='References\\n[1] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXivpreprint arXiv:1312.6114, 2013.\\n[2] Durk P Kingma, Tim Salimans, Rafal Jozefowicz, Xi Chen, Ilya Sutskever, and Max Welling. Improved varia-\\ntional inference with inverse autoregressive ﬂow. Advances inneuralinformation processing systems, 29, 2016.\\n[3] Casper Kaae Sønderby, Tapani Raiko, Lars Maaløe, Søren Kaae Sønderby, and Ole Winther. Ladder variational\\nautoencoders. Advances inneuralinformation processing systems, 29, 2016.\\n[4] Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning\\nusing nonequilibrium thermodynamics. In International Conference onMachine Learning, pages 2256–2265.\\nPMLR, 2015.\\n[5] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diﬀusion probabilistic models. Advances inNeural\\nInformation Processing Systems, 33:6840–6851, 2020.\\n[6] Diederik Kingma, Tim Salimans, Ben Poole, and Jonathan Ho. Variational diﬀusion models. Advances inneural\\ninformation processing systems, 34:21696–21707, 2021.\\n[7] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed\\nGhasemipour, Burcu Karagol Ayan, S Sara Mahdavi, Rapha Gontijo Lopes, et al. Photorealistic text-to-image\\ndiﬀusion models with deep language understanding. arXivpreprint arXiv:2205.11487, 2022.\\n[8] Bradley Efron. Tweedie’s formula and selection bias. JournaloftheAmerican Statistical Association, 106(496):\\n1602–1614, 2011.\\n[9] Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. Advances\\ninNeuralInformation Processing Systems, 32, 2019.\\n[10] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-\\nbased generative modeling through stochastic diﬀerential equations. arXivpreprint arXiv:2011.13456, 2020.\\n[11] Yang Song and Stefano Ermon. Improved techniques for training score-based generative models. Advances in\\nneuralinformation processing systems, 33:12438–12448, 2020.\\n[12] Yann LeCun, Sumit Chopra, Raia Hadsell, M Ranzato, and F Huang. A tutorial on energy-based learning.\\nPredicting structured data, 1(0), 2006.\\n[13] Yang Song and Diederik P Kingma. How to train your energy-based models. arXivpreprint arXiv:2101.03288,\\n2021.\\n[14] Aapo Hyvärinen and Peter Dayan. Estimation of non-normalized statistical models by score matching. Journal\\nofMachine Learning Research, 6(4), 2005.\\n[15] Saeed Saremi, Arash Mehrjou, Bernhard Schölkopf, and Aapo Hyvärinen. Deep energy estimator networks.\\narXivpreprint arXiv:1805.08306, 2018.\\n[16] Yang Song, Sahaj Garg, Jiaxin Shi, and Stefano Ermon. Sliced score matching: A scalable approach to density\\nand score estimation. In Uncertainty inArtiﬁcial Intelligence, pages 574–584. PMLR, 2020.\\n[17] Pascal Vincent. A connection between score matching and denoising autoencoders. Neuralcomputation, 23(7):\\n1661–1674, 2011.\\n[18] JonathanHo, ChitwanSaharia, WilliamChan, DavidJFleet, MohammadNorouzi, andTimSalimans. Cascaded\\ndiﬀusion models for high ﬁdelity image generation. J.Mach.Learn.Res., 23:47–1, 2022.\\n[19] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional\\nimage generation with clip latents. arXivpreprint arXiv:2204.06125, 2022.\\n[20] Prafulla Dhariwal and Alexander Nichol. Diﬀusion models beat gans on image synthesis. Advances inNeural\\nInformation Processing Systems, 34:8780–8794, 2021.\\n[21] Jonathan Ho and Tim Salimans. Classiﬁer-free diﬀusion guidance. In NeurIPS 2021Workshop onDeep\\nGenerative ModelsandDownstream Applications, 2021.\\n23', metadata={'source': 'diffusion_models.pdf', 'page': 22})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"diffusion_models.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the Question based on the context below. \n",
      "If you cant answer the question, reply \"I don't know!\"\n",
      "\n",
      "Context:Here is a context\n",
      "\n",
      "Question:Here is a question\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template= \"\"\"\n",
    "Answer the Question based on the context below. \n",
    "If you cant answer the question, reply \"I don't know!\"\n",
    "\n",
    "Context:{context}\n",
    "\n",
    "Question:{question}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt= PromptTemplate.from_template(template)\n",
    "print(prompt.format(context=\"Here is a context\", question=\"Here is a question\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], template='\\nAnswer the Question based on the context below. \\nIf you cant answer the question, reply \"I don\\'t know!\"\\n\\nContext:{context}\\n\\nQuestion:{question}\\n\\n')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | parser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Sure! Based on the context you provided, the answer to the question \"Where did I study?\" is likely \"BVRIT\".'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {   \n",
    "        \"context\": \"I have studied in BVRIT\",\n",
    "        \"question\": \"Where did i study?\" \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "vectorstore= DocArrayInMemorySearch.from_documents(pages, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Understanding Diﬀusion Models: A Uniﬁed Perspective\\nCalvin Luo\\nGoogle Research, Brain Team\\ncalvinluo@google.com\\nAugust 26, 2022\\nContents\\nIntroduction: Generative Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\\nBackground: ELBO, VAE, and Hierarchical VAE . . . . . . . . . . . . . . . . . . . . . . . . 2\\nEvidence Lower Bound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\\nVariational Autoencoders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\nHierarchical Variational Autoencoders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\nVariational Diﬀusion Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\nLearning Diﬀusion Noise Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\nThree Equivalent Interpretations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\nScore-based Generative Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\nGuidance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\nClassiﬁer Guidance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\nClassiﬁer-Free Guidance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\nClosing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\\nIntroduction: Generative Models\\nGiven observed samples xfrom a distribution of interest, the goal of a generative model is to learn to\\nmodelits true data distribution p(x). Once learned, we can generate new samples from our approximate\\nmodel at will. Furthermore, under some formulations, we are able to use the learned model to evaluate the\\nlikelihood of observed or sampled data as well.\\nThereareseveralwell-knowndirectionsincurrentliterature, thatwewillonlyintroducebrieﬂyatahighlevel.\\nGenerative Adversarial Networks (GANs) model the sampling procedure of a complex distribution, which\\nis learned in an adversarial manner. Another class of generative models, termed \"likelihood-based\", seeks\\nto learn a model that assigns a high likelihood to the observed data samples. This includes autoregressive\\nmodels, normalizing ﬂows, and Variational Autoencoders (VAEs). Another similar approach is energy-based\\nmodeling, in which a distribution is learned as an arbitrarily ﬂexible energy function that is then normalized.\\n1arXiv:2208.11970v1  [cs.LG]  25 Aug 2022', metadata={'source': 'diffusion_models.pdf', 'page': 0}),\n",
       " Document(page_content='Once again, γis a term that controls how much our learned conditional model cares about the conditioning\\ninformation. When γ= 0, the learned conditional model completely ignores the conditioner and learns an\\nunconditional diﬀusion model. When γ= 1, the model explicitly learns the vanilla conditional distribution\\nwithout guidance. When γ > 1, the diﬀusion model not only prioritizes the conditional score function,\\nbut also moves in the direction away from the unconditional score function. In other words, it reduces the\\nprobability of generating samples that do not use conditioning information, in favor of the samples that\\nexplicitly do. This also has the eﬀect of decreasing sample diversity at the cost of generating samples that\\naccurately match the conditioning information.\\nBecause learning two separate diﬀusion models is expensive, we can learn both the conditional and uncon-\\nditional diﬀusion models together as a singular conditional model; the unconditional diﬀusion model can be\\nqueriedbyreplacing theconditioning information withﬁxed constant values, suchaszeros. Thisis essentially\\nperforming random dropout on the conditioning information. Classiﬁer-Free Guidance is elegant because\\nit enables us greater control over our conditional generation procedure while requiring nothing beyond the\\ntraining of a singular diﬀusion model.\\nClosing\\nAllowustorecapitulateourﬁndingsoverthecourseofourexplorations. First, wederiveVariationalDiﬀusion\\nModels as a special case of a Markovian Hierarchical Variational Autoencoder, where three key assumptions\\nenable tractable computation and scalable optimization of the ELBO. We then prove that optimizing a VDM\\nboils down to learning a neural network to predict one of three potential objectives: the original source image\\nfrom any arbitrary noisiﬁcation of it, the original source noise from any arbitrarily noisiﬁed image, or the\\nscore function of a noisiﬁed image at any arbitrary noise level. Then, we dive deeper into what it means to\\nlearn the score function, and connect it explicitly with the perspective of Score-based Generative Modeling.\\nLastly, we cover how to learn a conditional distribution using diﬀusion models.\\nIn summary, diﬀusion models have shown incredible capabilities as generative models; indeed, they power\\nthe current state-of-the-art models on text-conditioned image generation such as Imagen and DALL-E 2.\\nFurthermore, the mathematics that enable these models are exceedingly elegant. However, there still remain\\na few drawbacks to consider:\\n•It is unlikely that this is how we, as humans, naturally model and generate data; we do not generate\\nsamples as random noise that we iteratively denoise.\\n•The VDM does not produce interpretable latents. Whereas a VAE would hopefully learn a structured\\nlatent space through the optimization of its encoder, in a VDM the encoder at each timestep is already\\ngiven as a linear Gaussian model and cannot be optimized ﬂexibly. Therefore, the intermediate latents\\nare restricted as just noisy versions of the original input.\\n•The latents are restricted to the same dimensionality as the original input, further frustrating eﬀorts\\nto learn meaningful, compressed latent structure.\\n•Sampling is an expensive procedure, as multiple denoising steps must be run under both formulations.\\nRecall that one of the restrictions is that a large enough number of timesteps Tis chosen to ensure the\\nﬁnal latent is completely Gaussian noise; during sampling we must iterate over all these timesteps to\\ngenerate a sample.\\nAs a ﬁnal note, the success of diﬀusion models highlights the power of Hierarchical VAEs as a generative\\nmodel. We have shown that when we generalize to inﬁnitelatent hierarchies, even if the encoder is trivial\\nand the latent dimension is ﬁxed and Markovian transitions are assumed, we are still able to learn powerful\\nmodels of data. This suggests that further performance gains can be achieved in the case of general, deep', metadata={'source': 'diffusion_models.pdf', 'page': 21}),\n",
       " Document(page_content='Recall that the KL Divergence between two Gaussian distributions is:\\nDKL(N(x;µx,Σx)∥N(y;µy,Σy)) =1\\n2[\\nlog|Σy|\\n|Σx|−d+tr(Σ−1\\nyΣx) + (µy−µx)TΣ−1\\ny(µy−µx)]\\n(86)\\nIn our case, where we can set the variances of the two Gaussians to match exactly, optimizing the KL\\nDivergence term reduces to minimizing the diﬀerence between the means of the two distributions:\\narg min\\nθDKL(q(xt−1|xt,x0)∥pθ(xt−1|xt))\\n= arg min\\nθDKL(N(xt−1;µq,Σq(t))∥N(xt−1;µθ,Σq(t))) (87)\\n= arg min\\nθ1\\n2[\\nlog|Σq(t)|\\n|Σq(t)|−d+tr(Σq(t)−1Σq(t)) + (µθ−µq)TΣq(t)−1(µθ−µq)]\\n(88)\\n= arg min\\nθ1\\n2[\\nlog 1−d+d+ (µθ−µq)TΣq(t)−1(µθ−µq)]\\n(89)\\n= arg min\\nθ1\\n2[\\n(µθ−µq)TΣq(t)−1(µθ−µq)]\\n(90)\\n= arg min\\nθ1\\n2[\\n(µθ−µq)T(\\nσ2\\nq(t)I)−1(µθ−µq)]\\n(91)\\n= arg min\\nθ1\\n2σ2q(t)[\\n∥µθ−µq∥2\\n2]\\n(92)\\nwhere we have written µqas shorthand for µq(xt,x0), andµθas shorthand for µθ(xt,t)for brevity. In\\nother words, we want to optimize a µθ(xt,t)that matches µq(xt,x0), which from our derived Equation 84,\\ntakes the form:\\nµq(xt,x0) =√αt(1−¯αt−1)xt+√¯αt−1(1−αt)x0\\n1−¯αt(93)\\nAsµθ(xt,t)also conditions on xt, we can match µq(xt,x0)closely by setting it to the following form:\\nµθ(xt,t) =√αt(1−¯αt−1)xt+√¯αt−1(1−αt)ˆxθ(xt,t)\\n1−¯αt(94)\\nwhere ˆxθ(xt,t)is parameterized by a neural network that seeks to predict x0from noisy image xtand time\\nindext. Then, the optimization problem simpliﬁes to:\\narg min\\nθDKL(q(xt−1|xt,x0)∥pθ(xt−1|xt))\\n=arg min\\nθDKL(N(xt−1;µq,Σq(t))∥N(xt−1;µθ,Σq(t))) (95)\\n=arg min\\nθ1\\n2σ2q(t)[\\ued79\\ued79\\ued79\\ued79√αt(1−¯αt−1)xt+√¯αt−1(1−αt)ˆxθ(xt,t)\\n1−¯αt−√αt(1−¯αt−1)xt+√¯αt−1(1−αt)x0\\n1−¯αt\\ued79\\ued79\\ued79\\ued792\\n2]\\n(96)\\n=arg min\\nθ1\\n2σ2q(t)[\\ued79\\ued79\\ued79\\ued79√¯αt−1(1−αt)ˆxθ(xt,t)\\n1−¯αt−√¯αt−1(1−αt)x0\\n1−¯αt\\ued79\\ued79\\ued79\\ued792\\n2]\\n(97)\\n=arg min\\nθ1\\n2σ2q(t)[\\ued79\\ued79\\ued79\\ued79√¯αt−1(1−αt)\\n1−¯αt(ˆxθ(xt,t)−x0)\\ued79\\ued79\\ued79\\ued792\\n2]\\n(98)\\n=arg min\\nθ1\\n2σ2q(t)¯αt−1(1−αt)2\\n(1−¯αt)2[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n(99)\\nTherefore, optimizing a VDM boils down to learning a neural network to predict the original ground truth\\nimage from an arbitrarily noisiﬁed version of it [5]. Furthermore, minimizing the summation term of our\\nderived ELBO objective (Equation 58) across all noise levels can be approximated by minimizing the expec-\\ntation over all timesteps:\\narg min\\nθEt∼U{2,T}[\\nEq(xt|x0)[DKL(q(xt−1|xt,x0)∥pθ(xt−1|xt))]]\\n(100)\\nwhich can then be optimized using stochastic samples over timesteps.\\n13', metadata={'source': 'diffusion_models.pdf', 'page': 12}),\n",
       " Document(page_content='Learning Diﬀusion Noise Parameters\\nLet us investigate how the noise parameters of a VDM can be jointly learned. One potential approach is to\\nmodelαtusing a neural network ˆαη(t)with parameters η. However, this is ineﬃcient as inference must be\\nperformedmultipletimesateachtimestep ttocompute ¯αt. Whereascachingcanmitigatethiscomputational\\ncost, we can also derive an alternate way to learn the diﬀusion noise parameters. By substituting our variance\\nequation from Equation 85 into our derived per-timestep objective in Equation 99, we can reduce:\\n1\\n2σ2q(t)¯αt−1(1−αt)2\\n(1−¯αt)2[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n=1\\n2(1−αt)(1−¯αt−1)\\n1−¯αt¯αt−1(1−αt)2\\n(1−¯αt)2[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n(101)\\n=1\\n21−¯αt\\n(1−αt)(1−¯αt−1)¯αt−1(1−αt)2\\n(1−¯αt)2[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n(102)\\n=1\\n2¯αt−1(1−αt)\\n(1−¯αt−1)(1−¯αt)[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n(103)\\n=1\\n2¯αt−1−¯αt\\n(1−¯αt−1)(1−¯αt)[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n(104)\\n=1\\n2¯αt−1−¯αt−1¯αt+ ¯αt−1¯αt−¯αt\\n(1−¯αt−1)(1−¯αt)[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n(105)\\n=1\\n2¯αt−1(1−¯αt)−¯αt(1−¯αt−1)\\n(1−¯αt−1)(1−¯αt)[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n(106)\\n=1\\n2(¯αt−1(1−¯αt)\\n(1−¯αt−1)(1−¯αt)−¯αt(1−¯αt−1)\\n(1−¯αt−1)(1−¯αt))[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n(107)\\n=1\\n2(¯αt−1\\n1−¯αt−1−¯αt\\n1−¯αt)[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n(108)\\nRecall from Equation 70 that q(xt|x0)is a Gaussian of form N(xt;√¯αtx0,(1−¯αt)I). Then, following the\\ndeﬁnition of the signal-to-noise ratio (SNR) as SNR =µ2\\nσ2, we can write the SNR at each timestep tas:\\nSNR(t) =¯αt\\n1−¯αt(109)\\nThen, our derived Equation 108 (and Equation 99) can be simpliﬁed as:\\n1\\n2σ2q(t)¯αt−1(1−αt)2\\n(1−¯αt)2[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n=1\\n2(SNR(t−1)−SNR(t))[\\n∥ˆxθ(xt,t)−x0∥2\\n2]\\n(110)\\nAsthenameimplies,theSNRrepresentstheratiobetweentheoriginalsignalandtheamountofnoisepresent;\\na higher SNR represents more signal and a lower SNR represents more noise. In a diﬀusion model, we require\\nthe SNR to monotonically decrease as timestep tincreases; this formalizes the notion that perturbed input\\nxtbecomes increasingly noisy over time, until it becomes identical to a standard Gaussian at t=T.\\nFollowing the simpliﬁcation of the objective in Equation 110, we can directly parameterize the SNR at each\\ntimestep using a neural network, and learn it jointly along with the diﬀusion model. As the SNR must\\nmonotonically decrease over time, we can represent it as:\\nSNR(t) =exp(−ωη(t)) (111)\\nwhereωη(t)is modeled as a monotonically increasing neural network with parameters η. Negating ωη(t)\\nresults in a monotonically decreasing function, whereas the exponential forces the resulting term to be\\npositive. Note that the objective in Equation 100 must now optimize over ηas well. By combining our\\nparameterization of SNR in Equation 111 with our deﬁnition of SNR in Equation 109, we can also explicitly\\nderive elegant forms for the value of ¯αtas well as for the value of 1−¯αt:\\n¯αt\\n1−¯αt=exp(−ωη(t)) (112)\\n∴¯αt=sigmoid (−ωη(t)) (113)\\n∴1−¯αt=sigmoid (ωη(t)) (114)\\nThese terms are necessary for a variety of computations; for example, during optimization, they are used to\\ncreate arbitrarily noisy xtfrom inputx0using the reparameterization trick, as derived in Equation 69.\\n14', metadata={'source': 'diffusion_models.pdf', 'page': 13})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "retriever.invoke(\"What are diffusion models?\")# Control the number of documents using retriever top_key=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Diffusion models are a class of generative models that model the underlying distribution of a dataset by diffusing noise into the data. The goal is to learn a neural network that can predict the original ground truth image from an arbitrarily noisy version of it. In other words, diffusion models are a type of generative model that can generate new data samples that are similar to the training data but with added noise.\\n\\nThe basic idea behind diffusion models is to define a probability distribution over the pixels of an image, and then use a neural network to transform this distribution into the original ground truth image. The key insight is that the distribution over the pixels can be defined using a diffusion process, which is a continuous-time Markov process. By defining the distribution over the pixels in terms of a diffusion process, it is possible to model the underlying structure of the data in a more flexible and general way than traditional generative models.\\n\\nThere are several types of diffusion models, including:\\n\\n1. Denoising autoencoders: These models consist of a neural network that takes the noisy input and outputs the clean image. The goal is to learn a mapping from the noisy input to the clean image.\\n2. Diffusion-based generative adversarial networks (GANs): These models consist of a neural network that generates samples from a probability distribution over the pixels of an image, and then uses another neural network to transform these samples into the original ground truth image. The goal is to learn a mapping from the noise to the clean image.\\n3. Non-local means denoising: These models use a non-local averaging operation to remove noise from an image. The idea is to average the values of neighboring pixels, rather than simply replacing each pixel with its local mean.\\n4. Spatially-varying denoising autoencoders: These models use a neural network that takes the noisy input and outputs the clean image, while also adapting the encoding process to the spatial variation of the noise.\\n\\nDiffusion models have several advantages over traditional generative models. They can model complex distributions and generate high-quality images with fewer parameters. They are also more flexible and general than traditional generative models, as they do not require a specific structure for the data distribution. Additionally, diffusion models can be trained using a variety of techniques, including maximum likelihood estimation and variational inference.\\n\\nHowever, diffusion models also have some limitations. They can be computationally expensive to train and evaluate, especially for large images. They may also suffer from overfitting, where the model becomes too specialized to the training data and fails to generalize well to new data. Finally, they may not perform as well as traditional generative models in terms of generating new, diverse samples that are similar to the training data but with added noise.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "chain = ({\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")} \n",
    "        | prompt\n",
    "        | model\n",
    "        | parser \n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"What are diffusion models?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are diffusion models? \n",
      "Answer: Diffusion models are a class of deep learning models that are designed to perform denoising, or removing noise from images, in a continuous and hierarchical manner. The basic idea behind diffusion models is to gradually corrupt an image over time by adding Gaussian noise, until the final output is identical to pure Gaussian noise. This process is depicted visually in Figure 3 of the paper.\n",
      "\n",
      "The key insight of diffusion models is that the optimization of the evidence lower bound (ELBO) can be used as a proxy for maximizing the log-likelihood of the data. Specifically, the ELBO is equal to the sum of the KL divergence between the approximate posterior and the true posterior, plus the negative log probability of the data given the approximate posterior. By optimizing the ELBO, diffusion models can learn to denoise images in a way that is consistent with the true posterior distribution.\n",
      "\n",
      "Diffusion models consist of two main components: a noise schedule, which determines how much noise should be added to the image at each step of the denoising process, and a diffusion process, which gradually corrupts the image by adding Gaussian noise. The noise schedule is typically chosen to be a power law decaying with time, while the diffusion process can be implemented using various techniques such as convolutional neural networks (CNNs) or generative adversarial networks (GANs).\n",
      "\n",
      "One advantage of diffusion models is that they do not require explicit access to the true posterior distribution, which can be difficult to compute in some cases. Instead, they use the ELBO as a proxy for maximizing the log-likelihood of the data, which can be computed more easily. This makes diffusion models useful for tasks where the true posterior distribution is difficult to obtain, such as image denoising in the presence of complex noise or corrupted data.\n",
      "\n",
      "In summary, diffusion models are a class of deep learning models that perform denoising by gradually corrupting an image over time using Gaussian noise. They use the evidence lower bound (ELBO) as a proxy for maximizing the log-likelihood of the data, and have been shown to be effective in removing various types of noise from images.\n",
      "\n",
      "Question: How are diffusion models different from Text generation LLMs\n",
      "Answer: \n",
      "Diffusion models and text generation LLMs are both deep learning models used in natural language processing, but they have some key differences:\n",
      "\n",
      "1. Architecture: Diffusion models are typically based on a chain-like architecture, where each layer is connected to the previous one through a linear transformation and an element-wise multiplication. Text generation LLMs, on the other hand, often use recurrent neural networks (RNNs) or transformer architectures.\n",
      "2. Training objective: Diffusion models are typically trained using a likelihood-based objective function, where the goal is to maximize the probability of generating realistic text given the input noise. Text generation LLMs, on the other hand, are often trained using a masked language modeling (MLM) objective function, where the goal is to predict the missing word in a sequence of tokens.\n",
      "3. Output: Diffusion models generate text one token at a time, while text generation LLMs generate complete sequences of tokens.\n",
      "4. Noise injection: Diffusion models do not inject noise into the input text, unlike text generation LLMs which often use noise injection techniques to improve the diversity and creativity of the generated text.\n",
      "5. Temperature: In diffusion models, the temperature parameter controls the complexity of the generated text, with higher temperatures resulting in more complex and diverse text, while lower temperatures result in simpler and more predictable text. In contrast, text generation LLMs do not have a direct analogue to temperature, but rather use techniques such as word masking or adding noise to the input text to control the complexity of the generated text.\n",
      "6. Evaluation metrics: Diffusion models are often evaluated using metrics such as perplexity, which measures how well the generated text fits the training data, and fluency, which measures the coherence and readability of the generated text. Text generation LLMs are typically evaluated using metrics such as the BLEU score, which measures the quality of the generated text compared to a reference text, and ROUGE score, which measures the quality of the generated text compared to a reference text in terms of its ability to mimic the style and structure of the reference text.\n",
      "7. Applications: Diffusion models are often used for tasks such as text completion, language translation, and text summarization, while text generation LLMs are often used for tasks such as content generation, chatbots, and automated writing.\n",
      "\n",
      "In summary, diffusion models and text generation LLMs are both deep learning models used in natural language processing, but they differ in their architecture, training objective, output, noise injection, temperature, evaluation metrics, and applications.\n",
      "\n",
      "Question: What are diffusion noise parameters?\n",
      "Answer: In the context of diffusion models, diffusion noise parameters refer to the parameters that control the amount of noise added to the original signal at each timestep during the diffusion process. These parameters include αt and βt, which determine the amount of noise added by the Gaussian noise model and the rate at which the noise is added, respectively.\n",
      "\n",
      "More specifically, αt represents the variance of the Gaussian noise added at each timestep, and βt represents the rate at which the noise is added over time. The value of these parameters can have a significant impact on the quality of the generated images, as they determine the amount of noise present in the image and the rate at which the noise accumulates over time.\n",
      "\n",
      "In order to optimize these parameters effectively, it is important to understand how they affect the generation process and to have a clear objective function that can be used to guide the optimization process. This involves defining a loss function that measures the quality of the generated images in terms of some desired metric, such as peak signal-to-noise ratio (PSNR) or structural similarity index (SSIM).\n",
      "\n",
      "By optimizing these parameters using techniques such as gradient descent or evolution strategies, it is possible to generate high-quality images that closely match the original input signal.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"What are diffusion models? \",\n",
    "    \"How are diffusion models different from Text generation LLMs\", \n",
    "    \"What are diffusion noise parameters?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print((f\"Question: {question}\"))\n",
    "    print(f\"Answer: {chain.invoke({'question': question})}\") # use stream or batch to answer a batch of question (parallel processing)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion models and text generation LLMs are both machine learning models used in natural language processing, but they have some key differences:\n",
      "\n",
      "1. Output structure: Diffusion models generate a continuous distribution over the input space, whereas text generation LLMs output a discrete sequence of words or tokens.\n",
      "2. Training objective: Diffusion models are typically trained using a denoising autoencoder-like objective, where the goal is to reconstruct the original input from a noisy version. Text generation LLMs, on the other hand, are often trained using a masked language modeling objective, where the goal is to predict the missing word or token in a sequence given the context.\n",
      "3. Input representation: Diffusion models typically represent the input as a continuous vector, whereas text generation LLMs may use a discrete representation such as a bag-of-words.\n",
      "4. Generative capacity: Text generation LLMs are generally considered more powerful generators of coherent and fluent text compared to diffusion models. This is because LLMs can generate longer sequences and capture longer-range dependencies in the input sequence.\n",
      "5. Training data: Diffusion models are typically trained on large datasets of text, whereas text generation LLMs may be trained on a combination of text and other types of data such as images or audio.\n",
      "6. Model architecture: Diffusion models typically use a series of non-linear transformations to transform the input into a continuous distribution, whereas text generation LLMs may use a combination of linear and non-linear transformations to model the structure of language.\n",
      "7. Evaluation metrics: The evaluation metrics used for diffusion models are different from those used for text generation LLMs. For example, diffusion models may be evaluated using metrics such as denoising capacity, disentanglement, or semantic coherence, whereas text generation LLMs may be evaluated using metrics such as perplexity, accuracy, or fluency.\n",
      "8. Task applications: Diffusion models are often used for tasks such as language modeling, text generation, and image-to-image translation, whereas text generation LLMs are often used for tasks such as text summarization, sentiment analysis, and question answering.\n",
      "\n",
      "In summary, diffusion models and text generation LLMs are both powerful tools in natural language processing, but they have different strengths and weaknesses, and are best suited for different tasks and applications."
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"question\": \"How are diffusion models different from Text generation LLMs?\"}):\n",
    "    print(s, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab= [{'page_number': 1, 'content': 'Hey this is a test PDF       '}, {'page_number': 2, 'content': 'Here is page 1     '}, {'page_number': 3, 'content': 'Here is page 2     '}, {'page_number': 4, 'content': 'Here is page 3  '}]\n",
    "type(ab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents.base import Document\n",
    "ab = [{'page_number': 1, 'content': 'Hey this is a test PDF       '}, \n",
    "      {'page_number': 2, 'content': 'Here is page 1     '}, \n",
    "      {'page_number': 3, 'content': 'Here is page 2     '}, \n",
    "      {'page_number': 4, 'content': 'Here is page 3  '}]\n",
    "\n",
    "documents = []\n",
    "\n",
    "for item in ab:\n",
    "    page_number = item['page_number']\n",
    "    page_content = item['content']  # Rename 'content' to 'page_content'\n",
    "    document = Document(page_content)\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Hey this is a test PDF       '),\n",
       " Document(page_content='Here is page 1     '),\n",
       " Document(page_content='Here is page 2     '),\n",
       " Document(page_content='Here is page 3  ')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "vectorstore= DocArrayInMemorySearch.from_documents(documents, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.docarray.in_memory.DocArrayInMemorySearch at 0x12196f490>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mod-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
